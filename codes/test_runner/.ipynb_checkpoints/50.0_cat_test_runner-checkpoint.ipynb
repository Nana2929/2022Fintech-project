{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16dde7eb-bd59-4ba1-b3c5-91f420ddb986",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üåà CategoryÔºàÂìÅÈ°ûÔºâ Test Runner\n",
    "\n",
    " - Fintech Project\n",
    "\n",
    " - b06102020 Ê•äÊô¥ÈõØ \n",
    "\n",
    " - 2022.05.27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a67bd-46d2-4dbb-bbc8-f6b8943c81cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. BERT prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6597c9-4aba-4517-8f4f-294d1e448488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avo727/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import joblib, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch \n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset, load_metric\n",
    "from transformers import BertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "testpath = './data/ÂìÅÈ°ûË≥áÊñôÈõÜ/cat_test_v2(question).csv'\n",
    "checkpoint_path = './checkpoints/0510-0939/model.ckpt'\n",
    "cat2idx_path = './category/cat2idx.pkl'\n",
    "cat2kw_path = './category/cat2kw.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e32454e3-1bd9-4904-ae27-c59a9f931df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f565e8a-cfe7-49f1-821c-797cb245e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat2idx = joblib.load(cat2idx_path)\n",
    "idx2cat = {v:k for k, v in cat2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e39727-cb48-4a9a-9908-f0318b29c5ae",
   "metadata": {},
   "source": [
    "#### 1-1. Testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ba7d82b7-07fc-4933-a50c-4864c9d0ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import preproc, collate_fn, compute_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1753138-828d-446f-b5d5-794db510a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(testpath)\n",
    "df[\"id\"] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d55ec65e-7d07-49d8-bb0d-97b8df82fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "530e1d14-014c-4fbf-bf38-feaaa6c291b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset  = testset.map(preproc(), batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b711d8e1-1234-4fc9-b647-869dc49b9826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.load(checkpoint_path)\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "531a4109-9830-411f-9dfa-117043ac8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = 'bert-base-chinese'\n",
    "batch_size = 20\n",
    "test_loader = DataLoader(testset, \n",
    "                        batch_size = batch_size, \n",
    "                        collate_fn=collate_fn(), shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c0d5a9-18a2-4354-a00a-1218822a9587",
   "metadata": {},
   "source": [
    "#### 1-2. Inferencing test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f78b9289-6ced-41f6-a343-aa011ae52a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "def inference(test_loader):\n",
    "    with torch.no_grad():\n",
    "        test_pairs = {'preds': [], \n",
    "                    'labels': []}\n",
    "        for id, batch in enumerate(test_loader):\n",
    "            inputs = batch['input_ids'].to(device)\n",
    "            attnmasks = batch['attention_mask'].to(device)\n",
    "            \n",
    "            logits = model(inputs, attnmasks).logits\n",
    "            preds = F.softmax(logits, dim = 1)\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            if 'label' in batch:\n",
    "                labels = batch['label'].to(device)\n",
    "                labels = labels.detach().cpu().numpy()\n",
    "                test_pairs['labels'].append(labels)\n",
    "            \n",
    "            test_pairs['preds'].append(preds)\n",
    "\n",
    "        # Note that we need to compute by dataset instead of by batch\n",
    "        test_preds = np.vstack(test_pairs['preds'])\n",
    "        if 'label' in batch:\n",
    "            test_labels = np.vstack(test_pairs['labels'])\n",
    "            test_acc = compute_accuracy(labels = test_labels, \n",
    "                                       preds = test_preds)\n",
    "        raw_test_preds = test_preds\n",
    "        predictions = np.where(test_preds <= 0.5, 0, 1)\n",
    "\n",
    "        print(\"üçé Finished inferencing testloader.\")\n",
    "        if 'label' in batch:\n",
    "            print(f\"[info]|VAL F1 macro: {test_acc['macro f1']:.3f}, \\\n",
    "                  weighted: {test_acc['weighted f1']:.3f}\")\n",
    "        else: print(\"[info] No labels available for this dataset.\")\n",
    "        return predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc1354d6-1aad-419a-9be2-b7ceede48148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçé Finished inferencing testloader.\n",
      "[info] No labels available for this dataset.\n"
     ]
    }
   ],
   "source": [
    "predictions = inference(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96a9f6b7-d111-49c7-a119-ba83126e79eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108851, 217)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98b1b393-68a1-4af0-a250-cf90b02a84db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving \n",
    "from datetime import datetime\n",
    "timenow = datetime.now().strftime('%m%d-%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eeca7187-5ad0-44ad-8324-8b9611450a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./predictions/0527-0801_test_predictions.pkl']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_path = './dataset/encoded_testset_50.0'\n",
    "testpred_path = f'./predictions/{timenow}_test_predictions.pkl'\n",
    "testset.save_to_disk(testset_path)\n",
    "joblib.dump(predictions, testpred_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35809f9-7ee9-4786-ac9a-98f4d909220b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Addtional: String-matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046653f2-9887-4d3e-9855-7a7329ccad8b",
   "metadata": {},
   "source": [
    "load poor classes examined from validation set \n",
    "\n",
    "load keywords mapping from classes to fasttext keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "724886d7-823d-45a3-93ed-6f47882cc601",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeload = '0527-0801'\n",
    "testset = testset_path = './dataset/encoded_testset_50.0'\n",
    "testpred_path = f'./predictions/{timeload}_test_predictions.pkl'\n",
    "import datasets\n",
    "# predictions\n",
    "predictions  = joblib.load(testpred_path)\n",
    "# test dataset\n",
    "testset = datasets.load_from_disk(testset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26253404-7f45-4f87-9ce7-21fc6ae77222",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat2kw = joblib.load(cat2kw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb167902-2219-42f5-bab9-17bfa87a4b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_path = f'./category/poor_classf1.pkl'\n",
    "# poor classes in validation set: those classes that have under 0.1 f1 score in validation set \n",
    "poorclasses = joblib.load(pc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c93271bd-41d4-4690-876b-8a853ee681e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Â∑ßÊãºÂú∞Â¢ä', 0.0, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poorclasses[0] \n",
    "# classname, val_f1, val_support "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b75921-e8a6-4970-a553-e9ebab7b35a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "poorc = [x[0] for x in poorclasses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfee0ce3-7792-4d39-a669-9058ecd38180",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = testset['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c34c493f-9081-41d7-a8db-ca247b860d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "poor_cat2kw = {k:v for k, v in cat2kw.items() if k in poorc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbb2cf90-9b45-4f09-82cc-7ffd54ef3737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "THR = 0.99\n",
    "# use valprobs\n",
    "def string_match(names, predictions, verbose = 1):\n",
    "    for i, name in enumerate(names):\n",
    "        # pred vector is the prediction proabability vector of i-th validation data \n",
    "        pred_vector = predictions[i, :]\n",
    "        # for the classes that have poor f1 score: \n",
    "        if verbose:\n",
    "            print(f'{i+1}. {name}')\n",
    "            print('\\t orig:', idx2cat[np.argmax(pred_vector)], np.max(pred_vector))\n",
    "        \n",
    "        for cat, pairs in poor_cat2kw.items():\n",
    "            \n",
    "            \n",
    "            kws = [x[0] for x in pairs]\n",
    "            kwprobs = [x[1] for x in pairs]\n",
    "            kwdict = {kw:kwprob for kw, kwprob in zip(kws, kwprobs)}\n",
    "            # use regex to find if the keyword appears in validation data's `name` \n",
    "            pat = re.compile(r'(?:{})'.format('|'.join(map(re.escape, kws))))\n",
    "            # `hits` means the number of unique keywords found in 'name'\n",
    "            hits = re.findall(pat, name)\n",
    "            # for those \"hit keywords\", add up their cos_similarity\n",
    "            # I personally call the summed cos_sim `cat_hit_probs` (category hit probability)\n",
    "            # which is not completely accurate so bear with it \n",
    "            \n",
    "            # !!!! REVISION 16:52 !!!!\n",
    "            cat_hit_probs = sum(kwdict[hit] for hit in hits)/len(hits) if len(hits) > 0 else 0\n",
    "            if verbose:\n",
    "                if cat_hit_probs > 0:\n",
    "                    print('\\t matched:', cat, cat_hit_probs)\n",
    "            \n",
    "            \n",
    "            # find the class' corresponding index\n",
    "            catid = cat2idx[cat]\n",
    "            # revise the prediction vector by plugging for this class the `cat_hit_probs`!!!\n",
    "            pred_vector[catid] = cat_hit_probs\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dbd2adc-4cdf-4a68-b126-cbf4bba7dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_probs = string_match(test_names, \n",
    "                                   predictions, \n",
    "                                   verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ac6e6-4601-42e1-b58d-75b5eee4de51",
   "metadata": {},
   "source": [
    "### 3. generate final predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b584490-0160-4a29-adc6-34703b1dbd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_THR = 0.990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d262fd4d-2b8b-4b01-8c0b-11ada8017efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "revised_preds = np.where(revised_probs <= best_THR, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88074cad-d939-4ef9-b70f-3770dde139a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time \n",
    "def generate_mapping(setnames, set_revised_preds, finals, tid):\n",
    "    multilabels = []\n",
    "    preds = []\n",
    "    n = len(setnames)\n",
    "    for i in range(n):\n",
    "        # print(name)\n",
    "        name=setnames[i]\n",
    "        pred = set_revised_preds[i, :]\n",
    "        predclasses = np.where(pred == 1)[0]\n",
    "        # print('\\t', predclasses)\n",
    "        # Â§öÊ®ôÁ±§\n",
    "        if len(predclasses) > 1:\n",
    "            multilabels.append((i, name, predclasses))\n",
    "        # probabilityÂàáÂ§™È´ò‰∫ÜÊ≤íÊúâclassË¢´È†êÊ∏¨ÔºåËÆìÂÆÉËá≥Â∞ëÁåú‰∏ÄÂÄãclass \n",
    "        if len(predclasses) < 1:\n",
    "            predclasses = [np.argmax(pred)]\n",
    "\n",
    "        product = ';'.join([idx2cat[pclass] for pclass in predclasses])\n",
    "        preds.append(product)\n",
    "    assert \n",
    "    finals[tid] = {'preds': preds, 'multilabels': multilabels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9ac0c9e5-39fd-483e-8cee-26eba6fcba82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10885"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsize//10 # 10885 # len(multilabels) 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455a442e-5b5a-4e8c-8a5b-8f3578153b40",
   "metadata": {},
   "source": [
    "takes too long, use threading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3dd9048-2a9c-4d14-ab78-f37f730ee24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread 0 works on: 0 3629\n",
      "thread 1 works on: 3629 7258\n",
      "thread 2 works on: 7258 10887\n",
      "thread 3 works on: 10887 14516\n",
      "thread 4 works on: 14516 18145\n",
      "thread 5 works on: 18145 21774\n",
      "thread 6 works on: 21774 25403\n",
      "thread 7 works on: 25403 29032\n",
      "thread 8 works on: 29032 32661\n",
      "thread 9 works on: 32661 36290\n",
      "thread 10 works on: 36290 39919\n",
      "thread 11 works on: 39919 43548\n",
      "thread 12 works on: 43548 47177\n",
      "thread 13 works on: 47177 50806\n",
      "thread 14 works on: 50806 54435\n",
      "thread 15 works on: 54435 58064\n",
      "thread 16 works on: 58064 61693\n",
      "thread 17 works on: 61693 65322\n",
      "thread 18 works on: 65322 68951\n",
      "thread 19 works on: 68951 72580\n",
      "thread 20 works on: 72580 76209\n",
      "thread 21 works on: 76209 79838\n",
      "thread 22 works on: 79838 83467\n",
      "thread 23 works on: 83467 87096\n",
      "thread 24 works on: 87096 90725\n",
      "thread 25 works on: 90725 94354\n",
      "thread 26 works on: 94354 97983\n",
      "thread 27 works on: 97983 101612\n",
      "thread 28 works on: 101612 105241\n",
      "thread 29 works on: 105241 108851\n",
      "Time spent on inferencing 108851 samples with 30 threads:       \n",
      "\t71.9080 seconds\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/6893968/how-to-get-the-return-value-from-a-thread-in-python\n",
    "import threading                                          \n",
    "from threading import Thread\n",
    "from math import ceil\n",
    "testsize = revised_preds.shape[0]\n",
    "\n",
    "split = 30\n",
    "finals = [None]*split\n",
    "threads = [None]*split\n",
    "one_portion = ceil(testsize/split)\n",
    "\n",
    "time_st = time.time()\n",
    "for tid in range(split):\n",
    "    start = tid*one_portion \n",
    "    end = min(start + one_portion, testsize)\n",
    "    print(f'thread {tid} works on:', start, end) # starting and ending index of inference \n",
    "    names_th = testset['name'][start:end]\n",
    "    preds_th = revised_preds[start:end]\n",
    "    threads[tid] = Thread(target = generate_mapping, \n",
    "                         args = (names_th, preds_th, finals, tid))\n",
    "    try:\n",
    "        threads[tid].start()\n",
    "    except:\n",
    "        print(f'\\tThread {tid} has error occurred.')\n",
    "        \n",
    "for tid in range(len(threads)):\n",
    "    threads[tid].join()   \n",
    "time_end = time.time()\n",
    "print(f'Time spent on inferencing {testsize} samples with {split} threads: \\\n",
    "      \\n\\t{(time_end - time_st):.4f} seconds' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51922de2-6ecd-4316-bee6-6077b87f28d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions = sum([d['preds'] for d in finals], [])\n",
    "len(final_predictions) == testsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd912020-6102-4483-adb9-98243d92004d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108851"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "665c293c-5804-449b-9d98-b0837d6f9e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108851"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0773a8f3-3025-4968-9e7a-a91f7213618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timenow = datetime.now().strftime('%m%d-%H%M')\n",
    "final_path = f'./predictions/{timenow}_test_pred.csv'\n",
    "df['product'] = final_predictions\n",
    "df.to_csv(final_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3373ef86-3585-468a-9f64-cd8e74baab68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 33615777792,\n",
       " 'available': 30548242432,\n",
       " 'percent': 9.1,\n",
       " 'used': 2578120704,\n",
       " 'free': 7729889280,\n",
       " 'active': 10354069504,\n",
       " 'inactive': 13469753344,\n",
       " 'buffers': 252899328,\n",
       " 'cached': 23054868480,\n",
       " 'shared': 15908864,\n",
       " 'slab': 1507663872}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import psutil\n",
    "# gives a single float value\n",
    "psutil.cpu_percent()\n",
    "# gives an object with many fields\n",
    "psutil.virtual_memory()\n",
    "# you can convert that object to a dictionary \n",
    "dict(psutil.virtual_memory()._asdict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

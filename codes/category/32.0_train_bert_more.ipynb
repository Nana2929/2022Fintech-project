{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naDF_AT5J5TU"
   },
   "source": [
    "# Fine-tuning BERT-2 [ÂìÅÈ°ûÂàÜÈ°ûÔºåÂ§öÊ®ôÁ±§]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Fintech Project\n",
    "\n",
    "Author: Ê•äÊô¥ÈõØ \n",
    "\n",
    "Date: 2022.5.10 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yozwzOC4Jfp4",
    "outputId": "16cc3dff-890d-4f6f-c324-ae4ef691e9da"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# maindir = '/content/drive/MyDrive/FinTech-final-project'\n",
    "# datadir = f'{maindir}/data'\n",
    "# spmdir = f'{maindir}/spm'\n",
    "# modeldir = f'{maindir}/models'\n",
    "# cat_df_path = f'{maindir}/Êù±Âê≥Ë™≤Á®ã_ÁôºÁ•®Ë≥áÊñôÈõÜ/ÂìÅÈ°ûË≥áÊñôÈõÜ/cat_train_v2.csv'\n",
    "datadir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "atDzGtn7JlqA"
   },
   "outputs": [],
   "source": [
    "# !pip -q install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KXufmtz5kwRP"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import random\n",
    "import torch \n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "t5l_8HsKI9dl"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_metric\n",
    "import datasets\n",
    "import joblib, sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './checkpoints/0510-0939/model.ckpt'\n",
    "datasets_path = './dataset/encoded_dataset_30.0'\n",
    "encoded_dataset = datasets.load_from_disk(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuWcrsaoehRk"
   },
   "source": [
    "## Reload BERT checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zfTBP_dQe5_o"
   },
   "outputs": [],
   "source": [
    "cat2idx = joblib.load(f'{datadir}/category/cat2idx.pkl')\n",
    "idx2cat = {v:k for k, v in cat2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OBuDgHUsegzC"
   },
   "outputs": [],
   "source": [
    "MODELNAME = 'bert-base-chinese'\n",
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODELNAME)\n",
    "N = len(idx2cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jo5WayPrlB4Q",
    "outputId": "2b25931a-18ec-4717-a438-78b53c5ead4c"
   },
   "outputs": [],
   "source": [
    "model = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S46i4ZwlGr08",
    "outputId": "4958da27-cbcd-41bd-9335-a5fbd6f072d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=217, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # A BertForSequenceClassification model based on bert-base-chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_kzVpv6-7U9i"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    keys = batch[0].keys()\n",
    "    # print(keys)\n",
    "    # 'id', 'name', 'label', 'seg_name', 'label_name', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'\n",
    "    to_tensor = ['input_ids', 'token_type_ids', 'attention_mask']\n",
    "    new_batch = {k:[d[k] for d in batch] for k in keys if k in to_tensor}\n",
    "    new_batch = tokenizer.pad(\n",
    "        new_batch,\n",
    "        padding= \"max_length\",\n",
    "        max_length= 100,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    label = [d['label'] for d in batch]\n",
    "    ids = [d['id'] for d in batch]\n",
    "    new_batch['label'] = torch.tensor(label, dtype=torch.float32)\n",
    "    new_batch[\"id\"] = torch.tensor(ids, dtype=torch.int64)\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hViob0EGjbvx"
   },
   "outputs": [],
   "source": [
    "extra_epochs = 15\n",
    "# the loaded model has been trained for 20 epochs already, and reaches: \n",
    "# VAL F1 macro: 0.529, weighted: 0.809\n",
    "# now we want to train more and train with different accuracy computation method\n",
    "# that is to set the zero_division value to 1 in f1_score() for those missed classes so that the result is more properly \n",
    "# evaluated \n",
    "\n",
    "batch_size = 200\n",
    "lr = 1e-5\n",
    "myseed = 1027 # 43 # 1123\n",
    "gast = 1\n",
    "wmst = 20\n",
    "weight_decay = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeding(myseed):\n",
    "    torch.manual_seed(myseed)\n",
    "    torch.cuda.manual_seed(myseed)\n",
    "    torch.cuda.manual_seed_all(myseed)\n",
    "    np.random.seed(myseed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seeding(myseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset to Dataloader\n",
    "Note that the dataset is saved from 30.0 script, otherwise we'll have train test splits mixed up in further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WGiGGBp6qHZL"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(encoded_dataset['train'], batch_size = batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "val_loader = DataLoader(encoded_dataset['test'], batch_size = batch_size, collate_fn=collate_fn, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48-JadvCnmzV"
   },
   "source": [
    "## Preparation for training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xj3LH2cCIgvq"
   },
   "outputs": [],
   "source": [
    "weight_decay = 0.05\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              weight_decay = weight_decay, \n",
    "                              lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "q47BgBrnI9q8"
   },
   "outputs": [],
   "source": [
    "# !pip -q install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gVLrUK_I9Dq",
    "outputId": "1851f873-ad7f-448f-ec36-46100491aa83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnana2929\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from datetime import datetime\n",
    "import os\n",
    "wandb.login()\n",
    "now = datetime.now()\n",
    "runname = now.strftime(\"%m%d-%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "c7q5sMaOIoMq",
    "outputId": "b834c371-45f5-42e2-9ae7-ac722b35e5bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2vrmhb49) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>‚ñÅ</td></tr><tr><td>train macro f1</td><td>‚ñÅ</td></tr><tr><td>train weighted f1</td><td>‚ñÅ</td></tr><tr><td>val loss</td><td>‚ñÅ</td></tr><tr><td>val macro f1</td><td>‚ñÅ</td></tr><tr><td>val weighted f1</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>4.54479</td></tr><tr><td>train macro f1</td><td>0.5333</td></tr><tr><td>train weighted f1</td><td>0.81856</td></tr><tr><td>val loss</td><td>4.55112</td></tr><tr><td>val macro f1</td><td>0.54818</td></tr><tr><td>val weighted f1</td><td>0.80938</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0510-0939</strong>: <a href=\"https://wandb.ai/nana2929/Fintech%20Project/runs/2vrmhb49\" target=\"_blank\">https://wandb.ai/nana2929/Fintech%20Project/runs/2vrmhb49</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220510_112629-2vrmhb49/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2vrmhb49). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/md0/data/avo727/fintech/wandb/run-20220510_114306-31cjr4au</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nana2929/Fintech%20Project/runs/31cjr4au\" target=\"_blank\">0510-0939</a></strong> to <a href=\"https://wandb.ai/nana2929/Fintech%20Project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/nana2929/Fintech%20Project/runs/31cjr4au?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f877a630a00>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project = \"Fintech Project\",\n",
    "           entity=\"nana2929\", \n",
    "           name = checkpoint_path.split('/')[-2],  #'0510-0939'\n",
    "           config = {\n",
    "               \"batch_size\": batch_size,\n",
    "               \"dataset\": \"È∫ªÂ∏ÉÊï∏Êìödataset1.0\",\n",
    "               \"learning_rate\": lr,\n",
    "               \"epochs\": extra_epochs, \n",
    "               \"note\": 'This is the further training on 0510-0939 checkpoint'\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "reEUdaexKG4b"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 10 11:26:32 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.46       Driver Version: 495.46       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:3E:00.0  On |                  Off |\n",
      "| 30%   40C    P2    62W / 230W |   1951MiB / 24248MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1612      G   /usr/lib/xorg/Xorg                 24MiB |\n",
      "|    0   N/A  N/A    134136      C   ...727/miniconda3/bin/python     1909MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfEV06DyqgL5"
   },
   "source": [
    "## Complete train loop\n",
    "- With logging, metrics, report to wandb\n",
    "- colab‰∏ägpuË®òÊÜ∂È´î‰∏çÂ§†ÔºåÂæóÊå™Âà∞server‰∏äË®ìÁ∑¥\n",
    "- batch_sizeÈñã1000ÊúÉÂ§™Â§ßÔºåÂèØÂòóË©¶200~800ÁöÑÁØÑÂúç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def compute_accuracy(labels, preds, zd = 1):\n",
    "    '''\n",
    "    REVISION WARNING:\n",
    "    Different from 30.0 where we set zero_division to 0 for those classes missed in validation set, \n",
    "    we now use 1 for computation of averaged f1. \n",
    "    \n",
    "    F1-score should be computed by the complete validation set! \n",
    "    Not by batch, SO BE SURE TO PASS IN two (val_size, nclass) arrays for inputs\n",
    "    '''\n",
    "    \n",
    "    preds = np.where(preds <= 0.5, 0, 1)\n",
    "    return {'macro f1': f1_score(labels, preds, average = 'macro', zero_division = zd), \n",
    "            'weighted f1': f1_score(labels, preds, average = 'weighted', zero_division = zd)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_ = np.array([0, 0.9, 2, 1, 0.1, 0.2]) <- simulate output predictions \n",
    "# y_ = np.where(y_ <= 0.5, 0, 1) \n",
    "# y = np.array([1, 1, 1, 1, 0, 0]) <- simulate real labels\n",
    "# f1_score(y, y_, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:02<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/35] |TRAIN loss: 4.541 |VAL loss:4.545,          \n",
      "         VAL F1 macro: 0.553, weighted: 0.816\n",
      "üèÜ Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:05<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/35] |TRAIN loss: 4.533 |VAL loss:4.537,          \n",
      "         VAL F1 macro: 0.570, weighted: 0.826\n",
      "üèÜ Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:04<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/35] |TRAIN loss: 4.532 |VAL loss:4.538,          \n",
      "         VAL F1 macro: 0.571, weighted: 0.826\n",
      "üèÜ Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/35] |TRAIN loss: 4.529 |VAL loss:4.533,          \n",
      "         VAL F1 macro: 0.578, weighted: 0.833\n",
      "üèÜ Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:04<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/35] |TRAIN loss: 4.525 |VAL loss:4.528,          \n",
      "         VAL F1 macro: 0.588, weighted: 0.839\n",
      "üèÜ Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 328/370 [02:43<00:21,  1.98it/s]wandb: Network error (ReadTimeout), entering retry loop.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:04<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/35] |TRAIN loss: 4.523 |VAL loss:4.527,          \n",
      "         VAL F1 macro: 0.600, weighted: 0.842\n",
      "üèÜ Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/35] |TRAIN loss: 4.520 |VAL loss:4.523,          \n",
      "         VAL F1 macro: 0.610, weighted: 0.847\n",
      "üèÜ Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:04<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/35] |TRAIN loss: 4.516 |VAL loss:4.520,          \n",
      "         VAL F1 macro: 0.617, weighted: 0.850\n",
      "üèÜ Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:04<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/35] |TRAIN loss: 4.516 |VAL loss:4.519,          \n",
      "         VAL F1 macro: 0.619, weighted: 0.852\n",
      "üèÜ Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/35] |TRAIN loss: 4.515 |VAL loss:4.518,          \n",
      "         VAL F1 macro: 0.620, weighted: 0.853\n",
      "üèÜ Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31/35] |TRAIN loss: 4.513 |VAL loss:4.518,          \n",
      "         VAL F1 macro: 0.617, weighted: 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:04<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32/35] |TRAIN loss: 4.515 |VAL loss:4.522,          \n",
      "         VAL F1 macro: 0.615, weighted: 0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:04<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33/35] |TRAIN loss: 4.513 |VAL loss:4.518,          \n",
      "         VAL F1 macro: 0.620, weighted: 0.854\n",
      "üèÜ Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34/35] |TRAIN loss: 4.512 |VAL loss:4.517,          \n",
      "         VAL F1 macro: 0.620, weighted: 0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 370/370 [03:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35/35] |TRAIN loss: 4.512 |VAL loss:4.516,          \n",
      "         VAL F1 macro: 0.629, weighted: 0.856\n",
      "üèÜ Saving model!\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "# %%wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.to(device)\n",
    "max_val_acc = -1\n",
    "\n",
    "\n",
    "# the already-trained epoch number\n",
    "base = 20 \n",
    "\n",
    "for epoch in range(extra_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = {'train': 0.0, \n",
    "                  'val': 0.0}\n",
    "    val_pairs = {'preds': [], \n",
    "                'labels': []}\n",
    "    train_pairs = {'preds': [],\n",
    "                  'labels': []}\n",
    "    model.train()\n",
    "    \n",
    "    for id, batch in enumerate(tqdm(train_loader)):\n",
    "        inputs = batch['input_ids'].to(device)\n",
    "        attnmasks = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        logits = model(inputs, attnmasks).logits\n",
    "        \n",
    "        preds = F.softmax(logits, dim = 1)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        # storing results \n",
    "        epoch_loss['train'] += loss.item()\n",
    "        \n",
    "        preds = preds.detach().cpu()\n",
    "        labels = labels.detach().cpu()\n",
    "        train_pairs['labels'].append(labels)\n",
    "        train_pairs['preds'].append(preds)\n",
    "        \n",
    "    \n",
    "    # Note that we need to compute by dataset instead of by batch\n",
    "    train_preds = torch.vstack(train_pairs['preds'])\n",
    "    train_labels = torch.vstack(train_pairs['labels'])\n",
    "    \n",
    "    train_acc = compute_accuracy(preds = train_preds, \n",
    "                                    labels = train_labels)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for id, batch in enumerate(val_loader):\n",
    "            inputs = batch['input_ids'].to(device)\n",
    "            attnmasks = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            logits = model(inputs, attnmasks).logits\n",
    "            # storing results \n",
    "            preds = F.softmax(logits, dim = 1)\n",
    "            loss = criterion(preds, labels)\n",
    "            \n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "            val_pairs['labels'].append(labels)\n",
    "            val_pairs['preds'].append(preds)\n",
    "            epoch_loss['val'] += loss.item()\n",
    "        \n",
    "        # Note that we need to compute by dataset instead of by batch\n",
    "        val_preds = np.vstack(val_pairs['preds'])\n",
    "        val_labels = np.vstack(val_pairs['labels'])\n",
    "        val_acc = compute_accuracy(labels = val_labels, \n",
    "                                       preds = val_preds)\n",
    "    wandb.log({\n",
    "        'train macro f1': train_acc['macro f1'],\n",
    "        'train weighted f1': train_acc['weighted f1'],\n",
    "        'train loss': epoch_loss['train']/len(train_loader),\n",
    "        'val macro f1': val_acc['macro f1'],\n",
    "        'val weighted f1':val_acc['weighted f1'],\n",
    "        'val loss': epoch_loss['val']/len(val_loader)\n",
    "        })\n",
    "    print(f\"[{epoch+1+base}/{extra_epochs+base}] |TRAIN loss: {epoch_loss['train']/len(train_loader):.3f} |VAL loss:{epoch_loss['val']/len(val_loader):.3f},\\\n",
    "          \\n         VAL F1 macro: {val_acc['macro f1']:.3f}, weighted: {val_acc['weighted f1']:.3f}\")\n",
    "    if val_acc['macro f1'] > max_val_acc:\n",
    "        torch.save(model, checkpoint_path)\n",
    "        print('üèÜ Saving model!')\n",
    "        max_val_acc = val_acc['macro f1']\n",
    "        best_val_pairs  = val_pairs\n",
    "        print('===================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ‰∫∫Â∑•Ê∑öÊ∂≤       0.95      0.95      0.95        21\n",
      "        ‰∏≠ÂºèÈ¶ôËÖ∏       0.71      1.00      0.83        57\n",
      "         ÂåñÂ¶ùÊ∞¥       0.98      0.98      0.98       173\n",
      "        Êàê‰∫∫ÁâôËÜè       0.85      1.00      0.92       403\n",
      "      Ê∞¥Ë∑Ø/ÂÅ•Ë°åÈûã       1.00      1.00      1.00         0\n",
      "         ÁÅ´ÈçãÊñô       0.98      1.00      0.99        57\n",
      "          Â•∂Áì∂       0.98      0.98      0.98        44\n",
      "        Â∑ßÊãºÂú∞Â¢ä       1.00      0.00      0.00         4\n",
      "        Âπ≥ÊùøÈõªËÖ¶       0.95      0.62      0.75        34\n",
      "       Á≠ÜË®òÂûãÈõªËÖ¶       0.83      0.92      0.87        48\n",
      "       Êô∫ÊÖßÂûãÊâãÊ©ü       0.85      0.93      0.89       148\n",
      "    Áì¶ÊñØÁàê(ÂªöÊàøÁî®)       1.00      0.00      0.00        14\n",
      "    Áì¶ÊñØÁàê(ÊîúÂ∏∂Âºè)       0.50      1.00      0.67        13\n",
      "       Áî≤Áâá/Áî≤Ë≤º       0.98      1.00      0.99        41\n",
      "         Áî≤Ê≤πËÜ†       1.00      0.00      0.00         3\n",
      "          ÂÜ∞ÁÆ±       1.00      1.00      1.00        38\n",
      "        ÂÆâÂÖ®Ê±ΩÂ∫ß       0.87      0.93      0.90        14\n",
      "        Êàê‰∫∫ÁâôÂà∑       0.74      1.00      0.85       239\n",
      "        Êàê‰∫∫Â•∂Á≤â       0.77      1.00      0.87        92\n",
      "        ÂÖíÁ´•ÁâôÂà∑       1.00      0.00      0.00        86\n",
      "       Êàê‰∫∫Á¥ôÂ∞øË§≤       1.00      1.00      1.00        45\n",
      "      ÊàêÈï∑ÂπºÂÖíÂ•∂Á≤â       1.00      0.00      0.00        21\n",
      "        Â™ΩÂ™ΩÂ•∂Á≤â       1.00      0.00      0.00         9\n",
      "         Êî∂Á¥çÊ´É       0.95      1.00      0.97        52\n",
      "      Á±≥Êºø/Ë±ÜÁ±≥Êºø       0.97      1.00      0.98        28\n",
      "          Áæä‰π≥       1.00      0.00      0.00         6\n",
      "        Ë•øÂºèÈ¶ôËÖ∏       1.00      0.00      0.00        23\n",
      "     ÂÜ∑Ê∞£/ÂÜ∑ÊöñÁ©∫Ë™ø       0.88      1.00      0.94        15\n",
      "        Âç≥È£üÈõûËÉ∏       0.91      1.00      0.95        20\n",
      "        Âç≥È£≤Â•∂Ëå∂       1.00      1.00      1.00       107\n",
      "        Âç≥È£≤ÂíñÂï°       1.00      0.99      0.99        76\n",
      "         Ê¥óÈ´ÆÁ≤æ       0.94      0.99      0.97       754\n",
      "         ÂíñÂï°Ë±Ü       1.00      1.00      1.00        46\n",
      "        Âç≥È£≤Á¥ÖËå∂       0.93      1.00      0.96       112\n",
      "       Âç≥È£≤ÁÑ°Á≥ñËå∂       1.00      0.00      0.00        81\n",
      "       Âç≥È£≤ÁÉèÈæçËå∂       0.69      1.00      0.81        24\n",
      "        Âç≥È£≤Á∂†Ëå∂       0.79      0.99      0.88       107\n",
      "        Âç≥Ê∫∂ÂíñÂï°       0.98      0.98      0.98       132\n",
      "          ÁúâÁ≠Ü       0.91      1.00      0.95       169\n",
      "         Âê∏Â°µÂô®       1.00      0.99      1.00       126\n",
      "         Ê¥óË°£Ê©ü       0.86      1.00      0.93        70\n",
      "         ÂêπÈ¢®Ê©ü       1.00      0.99      0.99        86\n",
      "     Â¶ùÂâç‰π≥/ÈöîÈõ¢Èúú       0.99      0.94      0.96       131\n",
      "         Âø´ÁÖÆÂ£∫       0.96      1.00      0.98        51\n",
      "     Âø´ÁÖÆÈ∫µ/‰πæÊãåÈ∫µ       1.00      0.00      0.00       109\n",
      "         Êùè‰ªÅÂ•∂       1.00      1.00      1.00        14\n",
      "         Ê≤êÊµ¥‰π≥       0.98      1.00      0.99       574\n",
      "         Ê¥óÈù¢‰π≥       0.97      0.99      0.98       570\n",
      "         Âç∏Â¶ùÊ∞¥       0.40      0.98      0.57        88\n",
      "         Ê¥óË°£Á≤æ       0.69      1.00      0.81       415\n",
      "         Ê¥óË°£Á≤â       1.00      0.00      0.00        73\n",
      " Ê¥óÈ´ÆÁ≤æ(Â¨∞ÂπºÁ´•/Â≠ïÂ©¶)       1.00      0.00      0.00        65\n",
      "          Èù¢ËÜú       1.00      1.00      1.00       378\n",
      "       Ë±ÜÂ•∂/Ë±Ü‰π≥       1.00      0.00      0.00        41\n",
      "      Ë±ÜÊºø/ÈªëË±ÜÊºø       0.66      0.99      0.79        78\n",
      "        Ë∫´È´î‰π≥Ê∂≤       0.96      1.00      0.98        88\n",
      "          Èò≤Êõ¨       0.95      0.88      0.91       106\n",
      "         ‰π≥ÈÖ∏Ëèå       1.00      0.00      0.00         8\n",
      "        ÂÖíÁ´•ÁâôËÜè       1.00      0.00      0.00        69\n",
      "       ÂÖíÁ´•Êº±Âè£Ê∞¥       0.96      1.00      0.98        26\n",
      "    ÂÖ∂‰ªñÂú∞Â¢ä(ÂÆ∂Áî®)       0.67      1.00      0.80        36\n",
      "         Âç∏Áî≤Ê∂≤       1.00      0.00      0.00         1\n",
      "         Âç∏Â¶ù‰π≥       1.00      0.00      0.00        50\n",
      "         Âç∏Â¶ùÊ≤π       1.00      0.00      0.00        47\n",
      "         Âç∏Â¶ùÊ£â       1.00      1.00      1.00        58\n",
      "        Âç∏Â¶ùÂáùËÜ†       0.82      0.85      0.84        27\n",
      "        Âç∏Â¶ùÊøïÂ∑æ       1.00      0.00      0.00         5\n",
      "         Âç∏Â¶ùÈúú       1.00      0.00      0.00        10\n",
      "         Âç∏Â¶ùÈú≤       1.00      0.00      0.00         2\n",
      "         ÂíñÂï°Ê©ü       1.00      1.00      1.00        32\n",
      "          ÈçãÂÖ∑       0.73      0.98      0.84       324\n",
      "         ÊûúÊ±ÅÊ©ü       1.00      1.00      1.00        18\n",
      "       Áãó‰πæÁ≥ßÁΩêÈ†≠       0.89      1.00      0.94       278\n",
      "         ÁãóÈõ∂È£ü       0.96      0.62      0.75        89\n",
      "         Ëä≥È¶ôË±Ü       1.00      1.00      1.00        52\n",
      "         ‰øù‰πÖ‰π≥       1.00      0.71      0.83        63\n",
      "         ‰øùÊ∫´ÊùØ       1.00      0.00      0.00         1\n",
      "         ‰øùÈö™Â•ó       0.99      0.99      0.99       100\n",
      "        ÂâçÂ∞éÁ≤æËèØ       1.00      0.00      0.00         3\n",
      "        ÁúºÈÉ®Á≤æËèØ       1.00      0.00      0.00        15\n",
      "         Á≤æËèØÊ∂≤       0.82      0.98      0.89       149\n",
      "         ÊåáÁî≤Ê≤π       0.98      1.00      0.99       167\n",
      "         ÊåâÊë©Ê§Ö       1.00      0.00      0.00         2\n",
      "         ÊüìÁúâËÜè       1.00      1.00      1.00        28\n",
      "         ÊüîËªüÁ≤æ       0.99      0.98      0.98        84\n",
      "         Ê¥óË°£ÁöÇ       1.00      0.40      0.57        20\n",
      "         Ê¥óË°£ÁêÉ       1.00      0.00      0.00        97\n",
      "          ÁúºÈúú       0.92      1.00      0.96        58\n",
      "         Ê¥óÁ¢óÊ©ü       1.00      0.00      0.00         4\n",
      "          ÁúâÁ≤â       0.94      0.94      0.94        33\n",
      "         ÁúâËÜ†Á≠Ü       1.00      0.00      0.00        17\n",
      "       Èù¢Èúú/‰π≥Èúú       0.83      1.00      0.91       228\n",
      "         È¶ôÊ∞õÊ©ü       1.00      0.00      0.00         5\n",
      "        È¶ôÊ∞õË†üÁá≠       1.00      1.00      1.00        19\n",
      "          ‰øÆÂÆπ       1.00      1.00      1.00        36\n",
      "         Á≤âÂ∫ïÊ∂≤       0.99      0.99      0.99       173\n",
      "          Á≤âÈ§Ö       0.99      1.00      0.99       141\n",
      "         BBÈúú       1.00      0.00      0.00        24\n",
      "         CCÈúú       1.00      0.00      0.00        14\n",
      "        ÂéüÂë≥Áâõ‰π≥       1.00      0.00      0.00         2\n",
      "          ÂîáÂΩ©       0.58      0.88      0.70        16\n",
      "         ÊüìÂîáÊ∂≤       1.00      1.00      1.00         0\n",
      "          ÂîáÈáâ       1.00      0.98      0.99        65\n",
      "         ÂîáÂΩ©Áõ§       1.00      0.00      0.00         4\n",
      "          ÂîáËÜè       1.00      0.00      0.00       242\n",
      "          ÂîáËúú       1.00      0.00      0.00        34\n",
      "         Ë≠∑ÂîáËÜè       0.46      1.00      0.63       241\n",
      "         Ë≠∑ÊâãÈúú       0.99      1.00      0.99       192\n",
      "         ÂîáÁ∑öÁ≠Ü       1.00      0.00      0.00         5\n",
      "          ÂîáÈú≤       1.00      1.00      1.00        17\n",
      "        Ê°å‰∏äÈõªËÖ¶       1.00      0.00      0.00        11\n",
      "         Ê∞£Ê≥°Ê∞¥       0.98      1.00      0.99       100\n",
      "         Ê∞£ÁÇ∏Èçã       1.00      0.00      0.00        21\n",
      "         Ê∂àÊØíÈçã       1.00      0.00      0.00         7\n",
      "     ÁÉòË°£Ê©ü/‰πæË°£Ê©ü       1.00      0.00      0.00        12\n",
      "         ÁÉòÁ¢óÊ©ü       0.88      1.00      0.94        30\n",
      "         ÁÉ§ËÇâÊû∂       1.00      0.00      0.00         5\n",
      "          ÁÉ§ÁÆ±       0.92      1.00      0.96        36\n",
      "       Áè™ËóªÂúüÂú∞Â¢ä       1.00      1.00      1.00        29\n",
      "         ÁõäÁîüËèå       0.90      0.99      0.94        70\n",
      "         Èô§ÊøïÊ©ü       0.99      1.00      1.00       127\n",
      "         ÂÅ•ËÖπÂô®       1.00      0.00      0.00         8\n",
      "       ÂïûÈà¥/ÊßìÈà¥       0.94      0.94      0.94        17\n",
      "          ÊßìÁâá       1.00      1.00      1.00         0\n",
      "          Âï§ÈÖí       0.99      0.91      0.95       416\n",
      "         ÁÜ±Ê∞¥Âô®       1.00      0.00      0.00        14\n",
      "       RTDË™øÈÖí       0.97      0.95      0.96       123\n",
      "         ÁúºÂΩ±Áõ§       0.84      1.00      0.91       151\n",
      "      ÈÄüÈ£üÈ∫µ/Ê≥°È∫µ       0.81      1.00      0.90       482\n",
      "         ÈÜ¨Ê≤πÈ°û       0.99      0.97      0.98       162\n",
      "       Ë≤ì‰πæÁ≥ßÁΩêÈ†≠       0.94      0.99      0.96       398\n",
      "         Á≤æËèØÊ≤π       1.00      0.00      0.00        18\n",
      "         Ë≤ìÈõ∂È£ü       0.96      0.68      0.80        76\n",
      "        Â∏∏Ê∫´ÈÜ¨ÂåÖ       0.97      1.00      0.99       246\n",
      "         ÊéÉÂú∞Ê©ü       0.96      1.00      0.98        24\n",
      "        ÊéíÊ≤πÁÖôÊ©ü       1.00      1.00      1.00         7\n",
      "        Ê∂≤Êô∂ÈõªË¶ñ       0.96      0.99      0.97        76\n",
      "       ÈõªË¶ñÈÅäÊà≤Ê©ü       0.94      1.00      0.97        30\n",
      "     Ê∑®Ê∞¥Âô®/ÊøæÊ∞¥Âô®       0.96      0.87      0.91        30\n",
      "         ÊøïÁ¥ôÂ∑æ       0.98      1.00      0.99       321\n",
      "        ÁúºÂîáÂç∏Â¶ù       1.00      0.00      0.00        34\n",
      "        ÁúºÂΩ±ÊâìÂ∫ï       1.00      0.00      0.00         5\n",
      "       ÁúºÂΩ±Âà∑/Ê£í       1.00      0.67      0.80        36\n",
      "         ÁúºÂΩ±Á≠Ü       1.00      0.00      0.00        12\n",
      "         ÁúºÂΩ±Ëúú       1.00      0.00      0.00         6\n",
      "          ËÖÆÁ¥Ö       1.00      0.99      0.99        85\n",
      "         ÁúºÂΩ±Èúú       1.00      0.00      0.00         3\n",
      "         ÁúºÁ∑öÊ∂≤       0.95      1.00      0.97        36\n",
      "        ÁúºÁ∑öËÜ†Á≠Ü       0.96      1.00      0.98        44\n",
      "        ÁúºÁ∑öÊ∂≤Á≠Ü       1.00      0.00      0.00        25\n",
      "         ÁúºÁ∑öÁ≠Ü       0.54      1.00      0.70        39\n",
      "         ÈáéÈ§êÂ¢ä       1.00      0.00      0.00         8\n",
      "        È∫•ÁâáÁ©ÄÈ°û       1.00      1.00      1.00       131\n",
      "         ÁáïÈ∫•Â•∂       0.98      1.00      0.99        52\n",
      "         Êô∫ÊÖßÈå∂       1.00      0.97      0.99        37\n",
      "          Ê£âÊ¢ù       1.00      1.00      1.00        56\n",
      "      Ê£âË§≤/ÂÆâÁù°Ë§≤       1.00      0.00      0.00        20\n",
      "          ÊπØÂúì       1.00      1.00      1.00        32\n",
      "           Ëè∏       0.95      0.97      0.96       345\n",
      "        Á¢≥ÈÖ∏È£≤Êñô       0.84      1.00      0.91       193\n",
      "         Ë∑ëÊ≠•Ê©ü       1.00      1.00      1.00         7\n",
      "    Â™ΩÂ™ΩËå∂(Âì∫‰π≥Ëå∂)       1.00      0.00      0.00         5\n",
      "         ÂæÆÊ≥¢Áàê       1.00      0.98      0.99        53\n",
      "          Ê§∞Â•∂       1.00      1.00      1.00         6\n",
      "         Ê∫´Â•∂Âô®       1.00      0.00      0.00         2\n",
      "          ÊªëÈº†       1.00      1.00      1.00       218\n",
      "         ÁëúÁèàÂ¢ä       1.00      0.00      0.00         4\n",
      "         Áù´ÊØõËÜè       1.00      1.00      1.00        90\n",
      "          Áù°Ë¢ã       0.72      1.00      0.84        39\n",
      "         ËëâÈªÉÁ¥†       1.00      0.99      0.99        96\n",
      "      Á∂≠‰ªñÂëΩB+C       1.00      0.00      0.00         8\n",
      "          ËëâÈÖ∏       1.00      0.00      0.00        11\n",
      "      ÈÅãÂãï/Ê©üËÉΩÊúç       0.98      0.99      0.98       395\n",
      "        Á∂≠‰ªñÂëΩB       0.50      0.99      0.66        93\n",
      "         ÈÅãÂãïÈûã       0.97      0.97      0.97       433\n",
      "         ÈõªÂ≠êÈçã       1.00      0.00      0.00        39\n",
      "          ÈõªÈçã       1.00      0.00      0.00        50\n",
      "         ÈõªÈ¢®Êâá       1.00      0.97      0.99        40\n",
      "         ÈõªÊöñÂô®       0.99      1.00      1.00       320\n",
      "         ÈõªÁ£ÅÁàê       0.96      1.00      0.98        24\n",
      "        ÈõªÁÜ±Ê∞¥Áì∂       0.78      1.00      0.88        46\n",
      "         Êª¥ÈõûÁ≤æ       0.64      1.00      0.78        51\n",
      "          Á≤æÊ≤π       1.00      1.00      1.00        28\n",
      "       Á∂≠‰ªñÂëΩÈ£≤Êñô       0.75      0.77      0.76        47\n",
      "        Á∂≠‰ªñÂëΩD       1.00      0.00      0.00        18\n",
      "        Á∂≠‰ªñÂëΩC       1.00      0.00      0.00        53\n",
      "          ËñëÈªÉ       0.94      1.00      0.97        32\n",
      "        Á∂≠‰ªñÂëΩE       1.00      0.00      0.00        16\n",
      "        ËÜ†ÂéüËõãÁôΩ       0.98      0.98      0.98        53\n",
      "          ËúúÁ≤â       0.94      1.00      0.97        83\n",
      "         ÈÅÆÁëïËÜè       0.97      1.00      0.99        37\n",
      "        ÂªöÊàøÁ¥ôÂ∑æ       1.00      0.94      0.97        49\n",
      "         ÊΩ§È´Æ‰π≥       0.99      1.00      0.99       132\n",
      "         Ë≠∑È´Æ‰π≥       1.00      0.96      0.98       354\n",
      "         Ë°õÁîüÁ¥ô       1.00      1.00      1.00       226\n",
      "         Ë°õÁîüÊ£â       0.96      1.00      0.98       132\n",
      "        Ë™øÂë≥Áâõ‰π≥       0.61      0.96      0.74        68\n",
      "        Ë™øÂë≥Ë±ÜÊºø       1.00      0.00      0.00         9\n",
      "         Ë™øÁêÜÊ©ü       0.85      1.00      0.92        11\n",
      "         ÈÅÆÁëïÊ∂≤       0.62      0.87      0.72        15\n",
      "         ÈÅÆÁëïÁ≠Ü       0.92      1.00      0.96        11\n",
      "         ÈÅÆÁëïËúú       1.00      0.00      0.00         9\n",
      "         ÈÅÆÁëïÁõ§       1.00      0.00      0.00         6\n",
      "        Ê©üËÉΩÁâõ‰π≥       1.00      0.00      0.00        14\n",
      "          ÈÆÆ‰π≥       0.97      0.97      0.97       158\n",
      "          ÂÑ™Ê†º       0.98      0.99      0.99       112\n",
      "         ÂÑ™ÈÖ™‰π≥       0.99      0.97      0.98        73\n",
      "       Â¨∞ÂπºÊâãÊé®Ëªä       1.00      0.00      0.00         1\n",
      "        Â¨∞Âπº‰π≥Ê∂≤       1.00      0.00      0.00         1\n",
      "        ËáâÈÉ®‰π≥Ê∂≤       0.99      0.96      0.98       168\n",
      "          ÈçµÁõ§       1.00      0.94      0.97       104\n",
      "         Êì¥È¶ôÁì∂       0.91      1.00      0.95        30\n",
      "     ÊøæÊéõ/ËÄ≥ÊéõÂíñÂï°       1.00      1.00      1.00        86\n",
      "          ÈõûÁ≤æ       1.00      0.00      0.00        30\n",
      "         Á§¶Ê≥âÊ∞¥       1.00      1.00      1.00       234\n",
      "        Ë≠∑ÂîáÁ≤æËèØ       1.00      0.00      0.00        10\n",
      "         DDÈúú       1.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.90      0.89      0.89     18537\n",
      "   macro avg       0.94      0.65      0.63     18537\n",
      "weighted avg       0.93      0.89      0.86     18537\n",
      " samples avg       0.90      0.89      0.89     18537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cat2idx = joblib.load(f'{datadir}/category/cat2idx.pkl')\n",
    "labels = sorted(cat2idx.items(), key = lambda x:x[1])\n",
    "keys = [x[0] for x in labels]\n",
    "preds = np.where(np.vstack(best_val_pairs['preds']) <= 0.5, 0, 1)\n",
    "labels = np.vstack(best_val_pairs['labels'])\n",
    "ZD = 1 \n",
    "print(classification_report(labels, \n",
    "                            preds, target_names= keys, zero_division = ZD))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "30.0-train-bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01b13f782153467b9d0d68bf91b584eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06225482a79348fcb5776e0bb2fe20ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b42037741a745deb22735ae12d38530": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "210744bebedf4db19e540d740a8a94a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a51529bbb2aa414b869622b79ae3df5c",
      "max": 74,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d99eed783dde4cbdabd46adf2a362fa1",
      "value": 74
     }
    },
    "2897cbe4bc0d442eac2bb039dd7f8c98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "453a460a9de14d13922b099287e328df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4a4be3b407e045e2b72b0a2c17b4df80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b8630e768c44bc69c4b820e8a835153": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_85faad92fd6c40de8b120a1fb261576d",
       "IPY_MODEL_4c7d760eca3b48d6bb4e8a725e2b0ca3",
       "IPY_MODEL_f915d3300d784acfac2a8dd4ab7690c6"
      ],
      "layout": "IPY_MODEL_2897cbe4bc0d442eac2bb039dd7f8c98"
     }
    },
    "4c7d760eca3b48d6bb4e8a725e2b0ca3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06225482a79348fcb5776e0bb2fe20ab",
      "max": 19,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_453a460a9de14d13922b099287e328df",
      "value": 19
     }
    },
    "54e665dc6b01421888f54208643410e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85faad92fd6c40de8b120a1fb261576d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9df3b53e252c446d91f8057a1e2735e8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b640c50a78a645bf85840e46c0c40171",
      "value": "100%"
     }
    },
    "9df3b53e252c446d91f8057a1e2735e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a51529bbb2aa414b869622b79ae3df5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a660b7e4cb0944a6952823dbb7ffa5df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b640c50a78a645bf85840e46c0c40171": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bad5fb2850fc4f1fbf441dc53ee56871": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f215d423ded448b6b8b18b573e1cd159",
       "IPY_MODEL_210744bebedf4db19e540d740a8a94a9",
       "IPY_MODEL_f2fc8d60bd6f44efa6e0594cc3afb1e4"
      ],
      "layout": "IPY_MODEL_54e665dc6b01421888f54208643410e6"
     }
    },
    "d99eed783dde4cbdabd46adf2a362fa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e44cf0e133184a9fbbeb57def39b92b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f215d423ded448b6b8b18b573e1cd159": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b42037741a745deb22735ae12d38530",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_4a4be3b407e045e2b72b0a2c17b4df80",
      "value": "100%"
     }
    },
    "f2fc8d60bd6f44efa6e0594cc3afb1e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a660b7e4cb0944a6952823dbb7ffa5df",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f7fe411fb8284039adb0e75c2153cf80",
      "value": " 74/74 [00:32&lt;00:00,  4.29ba/s]"
     }
    },
    "f7fe411fb8284039adb0e75c2153cf80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f915d3300d784acfac2a8dd4ab7690c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e44cf0e133184a9fbbeb57def39b92b9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_01b13f782153467b9d0d68bf91b584eb",
      "value": " 19/19 [00:04&lt;00:00,  4.70ba/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

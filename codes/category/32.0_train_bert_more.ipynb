{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naDF_AT5J5TU"
   },
   "source": [
    "# Fine-tuning BERT-2 [品類分類，多標籤]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Fintech Project\n",
    "\n",
    "Author: 楊晴雯 \n",
    "\n",
    "Date: 2022.5.10 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yozwzOC4Jfp4",
    "outputId": "16cc3dff-890d-4f6f-c324-ae4ef691e9da"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# maindir = '/content/drive/MyDrive/FinTech-final-project'\n",
    "# datadir = f'{maindir}/data'\n",
    "# spmdir = f'{maindir}/spm'\n",
    "# modeldir = f'{maindir}/models'\n",
    "# cat_df_path = f'{maindir}/東吳課程_發票資料集/品類資料集/cat_train_v2.csv'\n",
    "datadir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "atDzGtn7JlqA"
   },
   "outputs": [],
   "source": [
    "# !pip -q install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KXufmtz5kwRP"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import random\n",
    "import torch \n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "t5l_8HsKI9dl"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_metric\n",
    "import datasets\n",
    "import joblib, sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './checkpoints/0510-0939/model.ckpt'\n",
    "datasets_path = './dataset/encoded_dataset_30.0'\n",
    "encoded_dataset = datasets.load_from_disk(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuWcrsaoehRk"
   },
   "source": [
    "## Reload BERT checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zfTBP_dQe5_o"
   },
   "outputs": [],
   "source": [
    "cat2idx = joblib.load(f'{datadir}/category/cat2idx.pkl')\n",
    "idx2cat = {v:k for k, v in cat2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OBuDgHUsegzC"
   },
   "outputs": [],
   "source": [
    "MODELNAME = 'bert-base-chinese'\n",
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODELNAME)\n",
    "N = len(idx2cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jo5WayPrlB4Q",
    "outputId": "2b25931a-18ec-4717-a438-78b53c5ead4c"
   },
   "outputs": [],
   "source": [
    "model = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S46i4ZwlGr08",
    "outputId": "4958da27-cbcd-41bd-9335-a5fbd6f072d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=217, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # A BertForSequenceClassification model based on bert-base-chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_kzVpv6-7U9i"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    keys = batch[0].keys()\n",
    "    # print(keys)\n",
    "    # 'id', 'name', 'label', 'seg_name', 'label_name', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'\n",
    "    to_tensor = ['input_ids', 'token_type_ids', 'attention_mask']\n",
    "    new_batch = {k:[d[k] for d in batch] for k in keys if k in to_tensor}\n",
    "    new_batch = tokenizer.pad(\n",
    "        new_batch,\n",
    "        padding= \"max_length\",\n",
    "        max_length= 100,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    label = [d['label'] for d in batch]\n",
    "    ids = [d['id'] for d in batch]\n",
    "    new_batch['label'] = torch.tensor(label, dtype=torch.float32)\n",
    "    new_batch[\"id\"] = torch.tensor(ids, dtype=torch.int64)\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hViob0EGjbvx"
   },
   "outputs": [],
   "source": [
    "extra_epochs = 15\n",
    "# the loaded model has been trained for 20 epochs already, and reaches: \n",
    "# VAL F1 macro: 0.529, weighted: 0.809\n",
    "# now we want to train more and train with different accuracy computation method\n",
    "# that is to set the zero_division value to 1 in f1_score() for those missed classes so that the result is more properly \n",
    "# evaluated \n",
    "\n",
    "batch_size = 200\n",
    "lr = 1e-5\n",
    "myseed = 1027 # 43 # 1123\n",
    "gast = 1\n",
    "wmst = 20\n",
    "weight_decay = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeding(myseed):\n",
    "    torch.manual_seed(myseed)\n",
    "    torch.cuda.manual_seed(myseed)\n",
    "    torch.cuda.manual_seed_all(myseed)\n",
    "    np.random.seed(myseed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seeding(myseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset to Dataloader\n",
    "Note that the dataset is saved from 30.0 script, otherwise we'll have train test splits mixed up in further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WGiGGBp6qHZL"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(encoded_dataset['train'], batch_size = batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "val_loader = DataLoader(encoded_dataset['test'], batch_size = batch_size, collate_fn=collate_fn, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48-JadvCnmzV"
   },
   "source": [
    "## Preparation for training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xj3LH2cCIgvq"
   },
   "outputs": [],
   "source": [
    "weight_decay = 0.05\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              weight_decay = weight_decay, \n",
    "                              lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "q47BgBrnI9q8"
   },
   "outputs": [],
   "source": [
    "# !pip -q install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gVLrUK_I9Dq",
    "outputId": "1851f873-ad7f-448f-ec36-46100491aa83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnana2929\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from datetime import datetime\n",
    "import os\n",
    "wandb.login()\n",
    "now = datetime.now()\n",
    "runname = now.strftime(\"%m%d-%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "c7q5sMaOIoMq",
    "outputId": "b834c371-45f5-42e2-9ae7-ac722b35e5bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2vrmhb49) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>▁</td></tr><tr><td>train macro f1</td><td>▁</td></tr><tr><td>train weighted f1</td><td>▁</td></tr><tr><td>val loss</td><td>▁</td></tr><tr><td>val macro f1</td><td>▁</td></tr><tr><td>val weighted f1</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>4.54479</td></tr><tr><td>train macro f1</td><td>0.5333</td></tr><tr><td>train weighted f1</td><td>0.81856</td></tr><tr><td>val loss</td><td>4.55112</td></tr><tr><td>val macro f1</td><td>0.54818</td></tr><tr><td>val weighted f1</td><td>0.80938</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0510-0939</strong>: <a href=\"https://wandb.ai/nana2929/Fintech%20Project/runs/2vrmhb49\" target=\"_blank\">https://wandb.ai/nana2929/Fintech%20Project/runs/2vrmhb49</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220510_112629-2vrmhb49/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2vrmhb49). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/md0/data/avo727/fintech/wandb/run-20220510_114306-31cjr4au</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nana2929/Fintech%20Project/runs/31cjr4au\" target=\"_blank\">0510-0939</a></strong> to <a href=\"https://wandb.ai/nana2929/Fintech%20Project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/nana2929/Fintech%20Project/runs/31cjr4au?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f877a630a00>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project = \"Fintech Project\",\n",
    "           entity=\"nana2929\", \n",
    "           name = checkpoint_path.split('/')[-2],  #'0510-0939'\n",
    "           config = {\n",
    "               \"batch_size\": batch_size,\n",
    "               \"dataset\": \"麻布數據dataset1.0\",\n",
    "               \"learning_rate\": lr,\n",
    "               \"epochs\": extra_epochs, \n",
    "               \"note\": 'This is the further training on 0510-0939 checkpoint'\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "reEUdaexKG4b"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 10 11:26:32 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.46       Driver Version: 495.46       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000    Off  | 00000000:3E:00.0  On |                  Off |\n",
      "| 30%   40C    P2    62W / 230W |   1951MiB / 24248MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1612      G   /usr/lib/xorg/Xorg                 24MiB |\n",
      "|    0   N/A  N/A    134136      C   ...727/miniconda3/bin/python     1909MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfEV06DyqgL5"
   },
   "source": [
    "## Complete train loop\n",
    "- With logging, metrics, report to wandb\n",
    "- colab上gpu記憶體不夠，得挪到server上訓練\n",
    "- batch_size開1000會太大，可嘗試200~800的範圍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def compute_accuracy(labels, preds, zd = 1):\n",
    "    '''\n",
    "    REVISION WARNING:\n",
    "    Different from 30.0 where we set zero_division to 0 for those classes missed in validation set, \n",
    "    we now use 1 for computation of averaged f1. \n",
    "    \n",
    "    F1-score should be computed by the complete validation set! \n",
    "    Not by batch, SO BE SURE TO PASS IN two (val_size, nclass) arrays for inputs\n",
    "    '''\n",
    "    \n",
    "    preds = np.where(preds <= 0.5, 0, 1)\n",
    "    return {'macro f1': f1_score(labels, preds, average = 'macro', zero_division = zd), \n",
    "            'weighted f1': f1_score(labels, preds, average = 'weighted', zero_division = zd)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_ = np.array([0, 0.9, 2, 1, 0.1, 0.2]) <- simulate output predictions \n",
    "# y_ = np.where(y_ <= 0.5, 0, 1) \n",
    "# y = np.array([1, 1, 1, 1, 0, 0]) <- simulate real labels\n",
    "# f1_score(y, y_, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:02<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/35] |TRAIN loss: 4.541 |VAL loss:4.545,          \n",
      "         VAL F1 macro: 0.553, weighted: 0.816\n",
      "🏆 Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:05<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/35] |TRAIN loss: 4.533 |VAL loss:4.537,          \n",
      "         VAL F1 macro: 0.570, weighted: 0.826\n",
      "🏆 Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:04<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/35] |TRAIN loss: 4.532 |VAL loss:4.538,          \n",
      "         VAL F1 macro: 0.571, weighted: 0.826\n",
      "🏆 Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/35] |TRAIN loss: 4.529 |VAL loss:4.533,          \n",
      "         VAL F1 macro: 0.578, weighted: 0.833\n",
      "🏆 Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:04<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/35] |TRAIN loss: 4.525 |VAL loss:4.528,          \n",
      "         VAL F1 macro: 0.588, weighted: 0.839\n",
      "🏆 Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|███████████████████████████████████████████████████████████████████████▊         | 328/370 [02:43<00:21,  1.98it/s]wandb: Network error (ReadTimeout), entering retry loop.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:04<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/35] |TRAIN loss: 4.523 |VAL loss:4.527,          \n",
      "         VAL F1 macro: 0.600, weighted: 0.842\n",
      "🏆 Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/35] |TRAIN loss: 4.520 |VAL loss:4.523,          \n",
      "         VAL F1 macro: 0.610, weighted: 0.847\n",
      "🏆 Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:04<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/35] |TRAIN loss: 4.516 |VAL loss:4.520,          \n",
      "         VAL F1 macro: 0.617, weighted: 0.850\n",
      "🏆 Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:04<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/35] |TRAIN loss: 4.516 |VAL loss:4.519,          \n",
      "         VAL F1 macro: 0.619, weighted: 0.852\n",
      "🏆 Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/35] |TRAIN loss: 4.515 |VAL loss:4.518,          \n",
      "         VAL F1 macro: 0.620, weighted: 0.853\n",
      "🏆 Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31/35] |TRAIN loss: 4.513 |VAL loss:4.518,          \n",
      "         VAL F1 macro: 0.617, weighted: 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:04<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32/35] |TRAIN loss: 4.515 |VAL loss:4.522,          \n",
      "         VAL F1 macro: 0.615, weighted: 0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:04<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33/35] |TRAIN loss: 4.513 |VAL loss:4.518,          \n",
      "         VAL F1 macro: 0.620, weighted: 0.854\n",
      "🏆 Saving model!\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34/35] |TRAIN loss: 4.512 |VAL loss:4.517,          \n",
      "         VAL F1 macro: 0.620, weighted: 0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 370/370 [03:03<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35/35] |TRAIN loss: 4.512 |VAL loss:4.516,          \n",
      "         VAL F1 macro: 0.629, weighted: 0.856\n",
      "🏆 Saving model!\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "# %%wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.to(device)\n",
    "max_val_acc = -1\n",
    "\n",
    "\n",
    "# the already-trained epoch number\n",
    "base = 20 \n",
    "\n",
    "for epoch in range(extra_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = {'train': 0.0, \n",
    "                  'val': 0.0}\n",
    "    val_pairs = {'preds': [], \n",
    "                'labels': []}\n",
    "    train_pairs = {'preds': [],\n",
    "                  'labels': []}\n",
    "    model.train()\n",
    "    \n",
    "    for id, batch in enumerate(tqdm(train_loader)):\n",
    "        inputs = batch['input_ids'].to(device)\n",
    "        attnmasks = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        logits = model(inputs, attnmasks).logits\n",
    "        \n",
    "        preds = F.softmax(logits, dim = 1)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        # storing results \n",
    "        epoch_loss['train'] += loss.item()\n",
    "        \n",
    "        preds = preds.detach().cpu()\n",
    "        labels = labels.detach().cpu()\n",
    "        train_pairs['labels'].append(labels)\n",
    "        train_pairs['preds'].append(preds)\n",
    "        \n",
    "    \n",
    "    # Note that we need to compute by dataset instead of by batch\n",
    "    train_preds = torch.vstack(train_pairs['preds'])\n",
    "    train_labels = torch.vstack(train_pairs['labels'])\n",
    "    \n",
    "    train_acc = compute_accuracy(preds = train_preds, \n",
    "                                    labels = train_labels)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for id, batch in enumerate(val_loader):\n",
    "            inputs = batch['input_ids'].to(device)\n",
    "            attnmasks = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            logits = model(inputs, attnmasks).logits\n",
    "            # storing results \n",
    "            preds = F.softmax(logits, dim = 1)\n",
    "            loss = criterion(preds, labels)\n",
    "            \n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "            val_pairs['labels'].append(labels)\n",
    "            val_pairs['preds'].append(preds)\n",
    "            epoch_loss['val'] += loss.item()\n",
    "        \n",
    "        # Note that we need to compute by dataset instead of by batch\n",
    "        val_preds = np.vstack(val_pairs['preds'])\n",
    "        val_labels = np.vstack(val_pairs['labels'])\n",
    "        val_acc = compute_accuracy(labels = val_labels, \n",
    "                                       preds = val_preds)\n",
    "    wandb.log({\n",
    "        'train macro f1': train_acc['macro f1'],\n",
    "        'train weighted f1': train_acc['weighted f1'],\n",
    "        'train loss': epoch_loss['train']/len(train_loader),\n",
    "        'val macro f1': val_acc['macro f1'],\n",
    "        'val weighted f1':val_acc['weighted f1'],\n",
    "        'val loss': epoch_loss['val']/len(val_loader)\n",
    "        })\n",
    "    print(f\"[{epoch+1+base}/{extra_epochs+base}] |TRAIN loss: {epoch_loss['train']/len(train_loader):.3f} |VAL loss:{epoch_loss['val']/len(val_loader):.3f},\\\n",
    "          \\n         VAL F1 macro: {val_acc['macro f1']:.3f}, weighted: {val_acc['weighted f1']:.3f}\")\n",
    "    if val_acc['macro f1'] > max_val_acc:\n",
    "        torch.save(model, checkpoint_path)\n",
    "        print('🏆 Saving model!')\n",
    "        max_val_acc = val_acc['macro f1']\n",
    "        best_val_pairs  = val_pairs\n",
    "        print('===================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        人工淚液       0.95      0.95      0.95        21\n",
      "        中式香腸       0.71      1.00      0.83        57\n",
      "         化妝水       0.98      0.98      0.98       173\n",
      "        成人牙膏       0.85      1.00      0.92       403\n",
      "      水路/健行鞋       1.00      1.00      1.00         0\n",
      "         火鍋料       0.98      1.00      0.99        57\n",
      "          奶瓶       0.98      0.98      0.98        44\n",
      "        巧拼地墊       1.00      0.00      0.00         4\n",
      "        平板電腦       0.95      0.62      0.75        34\n",
      "       筆記型電腦       0.83      0.92      0.87        48\n",
      "       智慧型手機       0.85      0.93      0.89       148\n",
      "    瓦斯爐(廚房用)       1.00      0.00      0.00        14\n",
      "    瓦斯爐(攜帶式)       0.50      1.00      0.67        13\n",
      "       甲片/甲貼       0.98      1.00      0.99        41\n",
      "         甲油膠       1.00      0.00      0.00         3\n",
      "          冰箱       1.00      1.00      1.00        38\n",
      "        安全汽座       0.87      0.93      0.90        14\n",
      "        成人牙刷       0.74      1.00      0.85       239\n",
      "        成人奶粉       0.77      1.00      0.87        92\n",
      "        兒童牙刷       1.00      0.00      0.00        86\n",
      "       成人紙尿褲       1.00      1.00      1.00        45\n",
      "      成長幼兒奶粉       1.00      0.00      0.00        21\n",
      "        媽媽奶粉       1.00      0.00      0.00         9\n",
      "         收納櫃       0.95      1.00      0.97        52\n",
      "      米漿/豆米漿       0.97      1.00      0.98        28\n",
      "          羊乳       1.00      0.00      0.00         6\n",
      "        西式香腸       1.00      0.00      0.00        23\n",
      "     冷氣/冷暖空調       0.88      1.00      0.94        15\n",
      "        即食雞胸       0.91      1.00      0.95        20\n",
      "        即飲奶茶       1.00      1.00      1.00       107\n",
      "        即飲咖啡       1.00      0.99      0.99        76\n",
      "         洗髮精       0.94      0.99      0.97       754\n",
      "         咖啡豆       1.00      1.00      1.00        46\n",
      "        即飲紅茶       0.93      1.00      0.96       112\n",
      "       即飲無糖茶       1.00      0.00      0.00        81\n",
      "       即飲烏龍茶       0.69      1.00      0.81        24\n",
      "        即飲綠茶       0.79      0.99      0.88       107\n",
      "        即溶咖啡       0.98      0.98      0.98       132\n",
      "          眉筆       0.91      1.00      0.95       169\n",
      "         吸塵器       1.00      0.99      1.00       126\n",
      "         洗衣機       0.86      1.00      0.93        70\n",
      "         吹風機       1.00      0.99      0.99        86\n",
      "     妝前乳/隔離霜       0.99      0.94      0.96       131\n",
      "         快煮壺       0.96      1.00      0.98        51\n",
      "     快煮麵/乾拌麵       1.00      0.00      0.00       109\n",
      "         杏仁奶       1.00      1.00      1.00        14\n",
      "         沐浴乳       0.98      1.00      0.99       574\n",
      "         洗面乳       0.97      0.99      0.98       570\n",
      "         卸妝水       0.40      0.98      0.57        88\n",
      "         洗衣精       0.69      1.00      0.81       415\n",
      "         洗衣粉       1.00      0.00      0.00        73\n",
      " 洗髮精(嬰幼童/孕婦)       1.00      0.00      0.00        65\n",
      "          面膜       1.00      1.00      1.00       378\n",
      "       豆奶/豆乳       1.00      0.00      0.00        41\n",
      "      豆漿/黑豆漿       0.66      0.99      0.79        78\n",
      "        身體乳液       0.96      1.00      0.98        88\n",
      "          防曬       0.95      0.88      0.91       106\n",
      "         乳酸菌       1.00      0.00      0.00         8\n",
      "        兒童牙膏       1.00      0.00      0.00        69\n",
      "       兒童漱口水       0.96      1.00      0.98        26\n",
      "    其他地墊(家用)       0.67      1.00      0.80        36\n",
      "         卸甲液       1.00      0.00      0.00         1\n",
      "         卸妝乳       1.00      0.00      0.00        50\n",
      "         卸妝油       1.00      0.00      0.00        47\n",
      "         卸妝棉       1.00      1.00      1.00        58\n",
      "        卸妝凝膠       0.82      0.85      0.84        27\n",
      "        卸妝濕巾       1.00      0.00      0.00         5\n",
      "         卸妝霜       1.00      0.00      0.00        10\n",
      "         卸妝露       1.00      0.00      0.00         2\n",
      "         咖啡機       1.00      1.00      1.00        32\n",
      "          鍋具       0.73      0.98      0.84       324\n",
      "         果汁機       1.00      1.00      1.00        18\n",
      "       狗乾糧罐頭       0.89      1.00      0.94       278\n",
      "         狗零食       0.96      0.62      0.75        89\n",
      "         芳香豆       1.00      1.00      1.00        52\n",
      "         保久乳       1.00      0.71      0.83        63\n",
      "         保溫杯       1.00      0.00      0.00         1\n",
      "         保險套       0.99      0.99      0.99       100\n",
      "        前導精華       1.00      0.00      0.00         3\n",
      "        眼部精華       1.00      0.00      0.00        15\n",
      "         精華液       0.82      0.98      0.89       149\n",
      "         指甲油       0.98      1.00      0.99       167\n",
      "         按摩椅       1.00      0.00      0.00         2\n",
      "         染眉膏       1.00      1.00      1.00        28\n",
      "         柔軟精       0.99      0.98      0.98        84\n",
      "         洗衣皂       1.00      0.40      0.57        20\n",
      "         洗衣球       1.00      0.00      0.00        97\n",
      "          眼霜       0.92      1.00      0.96        58\n",
      "         洗碗機       1.00      0.00      0.00         4\n",
      "          眉粉       0.94      0.94      0.94        33\n",
      "         眉膠筆       1.00      0.00      0.00        17\n",
      "       面霜/乳霜       0.83      1.00      0.91       228\n",
      "         香氛機       1.00      0.00      0.00         5\n",
      "        香氛蠟燭       1.00      1.00      1.00        19\n",
      "          修容       1.00      1.00      1.00        36\n",
      "         粉底液       0.99      0.99      0.99       173\n",
      "          粉餅       0.99      1.00      0.99       141\n",
      "         BB霜       1.00      0.00      0.00        24\n",
      "         CC霜       1.00      0.00      0.00        14\n",
      "        原味牛乳       1.00      0.00      0.00         2\n",
      "          唇彩       0.58      0.88      0.70        16\n",
      "         染唇液       1.00      1.00      1.00         0\n",
      "          唇釉       1.00      0.98      0.99        65\n",
      "         唇彩盤       1.00      0.00      0.00         4\n",
      "          唇膏       1.00      0.00      0.00       242\n",
      "          唇蜜       1.00      0.00      0.00        34\n",
      "         護唇膏       0.46      1.00      0.63       241\n",
      "         護手霜       0.99      1.00      0.99       192\n",
      "         唇線筆       1.00      0.00      0.00         5\n",
      "          唇露       1.00      1.00      1.00        17\n",
      "        桌上電腦       1.00      0.00      0.00        11\n",
      "         氣泡水       0.98      1.00      0.99       100\n",
      "         氣炸鍋       1.00      0.00      0.00        21\n",
      "         消毒鍋       1.00      0.00      0.00         7\n",
      "     烘衣機/乾衣機       1.00      0.00      0.00        12\n",
      "         烘碗機       0.88      1.00      0.94        30\n",
      "         烤肉架       1.00      0.00      0.00         5\n",
      "          烤箱       0.92      1.00      0.96        36\n",
      "       珪藻土地墊       1.00      1.00      1.00        29\n",
      "         益生菌       0.90      0.99      0.94        70\n",
      "         除濕機       0.99      1.00      1.00       127\n",
      "         健腹器       1.00      0.00      0.00         8\n",
      "       啞鈴/槓鈴       0.94      0.94      0.94        17\n",
      "          槓片       1.00      1.00      1.00         0\n",
      "          啤酒       0.99      0.91      0.95       416\n",
      "         熱水器       1.00      0.00      0.00        14\n",
      "       RTD調酒       0.97      0.95      0.96       123\n",
      "         眼影盤       0.84      1.00      0.91       151\n",
      "      速食麵/泡麵       0.81      1.00      0.90       482\n",
      "         醬油類       0.99      0.97      0.98       162\n",
      "       貓乾糧罐頭       0.94      0.99      0.96       398\n",
      "         精華油       1.00      0.00      0.00        18\n",
      "         貓零食       0.96      0.68      0.80        76\n",
      "        常溫醬包       0.97      1.00      0.99       246\n",
      "         掃地機       0.96      1.00      0.98        24\n",
      "        排油煙機       1.00      1.00      1.00         7\n",
      "        液晶電視       0.96      0.99      0.97        76\n",
      "       電視遊戲機       0.94      1.00      0.97        30\n",
      "     淨水器/濾水器       0.96      0.87      0.91        30\n",
      "         濕紙巾       0.98      1.00      0.99       321\n",
      "        眼唇卸妝       1.00      0.00      0.00        34\n",
      "        眼影打底       1.00      0.00      0.00         5\n",
      "       眼影刷/棒       1.00      0.67      0.80        36\n",
      "         眼影筆       1.00      0.00      0.00        12\n",
      "         眼影蜜       1.00      0.00      0.00         6\n",
      "          腮紅       1.00      0.99      0.99        85\n",
      "         眼影霜       1.00      0.00      0.00         3\n",
      "         眼線液       0.95      1.00      0.97        36\n",
      "        眼線膠筆       0.96      1.00      0.98        44\n",
      "        眼線液筆       1.00      0.00      0.00        25\n",
      "         眼線筆       0.54      1.00      0.70        39\n",
      "         野餐墊       1.00      0.00      0.00         8\n",
      "        麥片穀類       1.00      1.00      1.00       131\n",
      "         燕麥奶       0.98      1.00      0.99        52\n",
      "         智慧錶       1.00      0.97      0.99        37\n",
      "          棉條       1.00      1.00      1.00        56\n",
      "      棉褲/安睡褲       1.00      0.00      0.00        20\n",
      "          湯圓       1.00      1.00      1.00        32\n",
      "           菸       0.95      0.97      0.96       345\n",
      "        碳酸飲料       0.84      1.00      0.91       193\n",
      "         跑步機       1.00      1.00      1.00         7\n",
      "    媽媽茶(哺乳茶)       1.00      0.00      0.00         5\n",
      "         微波爐       1.00      0.98      0.99        53\n",
      "          椰奶       1.00      1.00      1.00         6\n",
      "         溫奶器       1.00      0.00      0.00         2\n",
      "          滑鼠       1.00      1.00      1.00       218\n",
      "         瑜珈墊       1.00      0.00      0.00         4\n",
      "         睫毛膏       1.00      1.00      1.00        90\n",
      "          睡袋       0.72      1.00      0.84        39\n",
      "         葉黃素       1.00      0.99      0.99        96\n",
      "      維他命B+C       1.00      0.00      0.00         8\n",
      "          葉酸       1.00      0.00      0.00        11\n",
      "      運動/機能服       0.98      0.99      0.98       395\n",
      "        維他命B       0.50      0.99      0.66        93\n",
      "         運動鞋       0.97      0.97      0.97       433\n",
      "         電子鍋       1.00      0.00      0.00        39\n",
      "          電鍋       1.00      0.00      0.00        50\n",
      "         電風扇       1.00      0.97      0.99        40\n",
      "         電暖器       0.99      1.00      1.00       320\n",
      "         電磁爐       0.96      1.00      0.98        24\n",
      "        電熱水瓶       0.78      1.00      0.88        46\n",
      "         滴雞精       0.64      1.00      0.78        51\n",
      "          精油       1.00      1.00      1.00        28\n",
      "       維他命飲料       0.75      0.77      0.76        47\n",
      "        維他命D       1.00      0.00      0.00        18\n",
      "        維他命C       1.00      0.00      0.00        53\n",
      "          薑黃       0.94      1.00      0.97        32\n",
      "        維他命E       1.00      0.00      0.00        16\n",
      "        膠原蛋白       0.98      0.98      0.98        53\n",
      "          蜜粉       0.94      1.00      0.97        83\n",
      "         遮瑕膏       0.97      1.00      0.99        37\n",
      "        廚房紙巾       1.00      0.94      0.97        49\n",
      "         潤髮乳       0.99      1.00      0.99       132\n",
      "         護髮乳       1.00      0.96      0.98       354\n",
      "         衛生紙       1.00      1.00      1.00       226\n",
      "         衛生棉       0.96      1.00      0.98       132\n",
      "        調味牛乳       0.61      0.96      0.74        68\n",
      "        調味豆漿       1.00      0.00      0.00         9\n",
      "         調理機       0.85      1.00      0.92        11\n",
      "         遮瑕液       0.62      0.87      0.72        15\n",
      "         遮瑕筆       0.92      1.00      0.96        11\n",
      "         遮瑕蜜       1.00      0.00      0.00         9\n",
      "         遮瑕盤       1.00      0.00      0.00         6\n",
      "        機能牛乳       1.00      0.00      0.00        14\n",
      "          鮮乳       0.97      0.97      0.97       158\n",
      "          優格       0.98      0.99      0.99       112\n",
      "         優酪乳       0.99      0.97      0.98        73\n",
      "       嬰幼手推車       1.00      0.00      0.00         1\n",
      "        嬰幼乳液       1.00      0.00      0.00         1\n",
      "        臉部乳液       0.99      0.96      0.98       168\n",
      "          鍵盤       1.00      0.94      0.97       104\n",
      "         擴香瓶       0.91      1.00      0.95        30\n",
      "     濾掛/耳掛咖啡       1.00      1.00      1.00        86\n",
      "          雞精       1.00      0.00      0.00        30\n",
      "         礦泉水       1.00      1.00      1.00       234\n",
      "        護唇精華       1.00      0.00      0.00        10\n",
      "         DD霜       1.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.90      0.89      0.89     18537\n",
      "   macro avg       0.94      0.65      0.63     18537\n",
      "weighted avg       0.93      0.89      0.86     18537\n",
      " samples avg       0.90      0.89      0.89     18537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cat2idx = joblib.load(f'{datadir}/category/cat2idx.pkl')\n",
    "labels = sorted(cat2idx.items(), key = lambda x:x[1])\n",
    "keys = [x[0] for x in labels]\n",
    "preds = np.where(np.vstack(best_val_pairs['preds']) <= 0.5, 0, 1)\n",
    "labels = np.vstack(best_val_pairs['labels'])\n",
    "ZD = 1 \n",
    "print(classification_report(labels, \n",
    "                            preds, target_names= keys, zero_division = ZD))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "30.0-train-bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01b13f782153467b9d0d68bf91b584eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06225482a79348fcb5776e0bb2fe20ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b42037741a745deb22735ae12d38530": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "210744bebedf4db19e540d740a8a94a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a51529bbb2aa414b869622b79ae3df5c",
      "max": 74,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d99eed783dde4cbdabd46adf2a362fa1",
      "value": 74
     }
    },
    "2897cbe4bc0d442eac2bb039dd7f8c98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "453a460a9de14d13922b099287e328df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4a4be3b407e045e2b72b0a2c17b4df80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b8630e768c44bc69c4b820e8a835153": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_85faad92fd6c40de8b120a1fb261576d",
       "IPY_MODEL_4c7d760eca3b48d6bb4e8a725e2b0ca3",
       "IPY_MODEL_f915d3300d784acfac2a8dd4ab7690c6"
      ],
      "layout": "IPY_MODEL_2897cbe4bc0d442eac2bb039dd7f8c98"
     }
    },
    "4c7d760eca3b48d6bb4e8a725e2b0ca3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06225482a79348fcb5776e0bb2fe20ab",
      "max": 19,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_453a460a9de14d13922b099287e328df",
      "value": 19
     }
    },
    "54e665dc6b01421888f54208643410e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85faad92fd6c40de8b120a1fb261576d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9df3b53e252c446d91f8057a1e2735e8",
      "placeholder": "​",
      "style": "IPY_MODEL_b640c50a78a645bf85840e46c0c40171",
      "value": "100%"
     }
    },
    "9df3b53e252c446d91f8057a1e2735e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a51529bbb2aa414b869622b79ae3df5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a660b7e4cb0944a6952823dbb7ffa5df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b640c50a78a645bf85840e46c0c40171": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bad5fb2850fc4f1fbf441dc53ee56871": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f215d423ded448b6b8b18b573e1cd159",
       "IPY_MODEL_210744bebedf4db19e540d740a8a94a9",
       "IPY_MODEL_f2fc8d60bd6f44efa6e0594cc3afb1e4"
      ],
      "layout": "IPY_MODEL_54e665dc6b01421888f54208643410e6"
     }
    },
    "d99eed783dde4cbdabd46adf2a362fa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e44cf0e133184a9fbbeb57def39b92b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f215d423ded448b6b8b18b573e1cd159": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b42037741a745deb22735ae12d38530",
      "placeholder": "​",
      "style": "IPY_MODEL_4a4be3b407e045e2b72b0a2c17b4df80",
      "value": "100%"
     }
    },
    "f2fc8d60bd6f44efa6e0594cc3afb1e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a660b7e4cb0944a6952823dbb7ffa5df",
      "placeholder": "​",
      "style": "IPY_MODEL_f7fe411fb8284039adb0e75c2153cf80",
      "value": " 74/74 [00:32&lt;00:00,  4.29ba/s]"
     }
    },
    "f7fe411fb8284039adb0e75c2153cf80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f915d3300d784acfac2a8dd4ab7690c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e44cf0e133184a9fbbeb57def39b92b9",
      "placeholder": "​",
      "style": "IPY_MODEL_01b13f782153467b9d0d68bf91b584eb",
      "value": " 19/19 [00:04&lt;00:00,  4.70ba/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

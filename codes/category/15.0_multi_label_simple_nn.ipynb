{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15.0-multi-label-simple_nn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Fintech Final Project\n",
        "## Category: multi-label classification \n",
        "Author: Nana\n",
        "\n",
        "Date: Created at 2022.4.14\n"
      ],
      "metadata": {
        "id": "RqnHVgUmy9nI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAz_HOx-fKBM",
        "outputId": "7fce5aea-c3d0-4a03-aa6a-5c1f14d12034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "maindir = '/content/drive/MyDrive/FinTech-final-project'\n",
        "datadir = f'{maindir}/data'\n",
        "spmdir = f'{maindir}/spm'\n",
        "modeldir = f'{maindir}/models'\n",
        "cat_df_path = f'{maindir}/東吳課程_發票資料集/品類資料集/cat_train_v2.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: Classifying fasttext embeddings\n",
        "2 linear layers "
      ],
      "metadata": {
        "id": "JWPMgzB3gmaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib, sys"
      ],
      "metadata": {
        "id": "_f3C-RkYfTM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# required for skmultilearn (can skip if not using the package)\n",
        "# # follow the instructions on https://github.com/thunlp/OpenNE"
      ],
      "metadata": {
        "id": "oLc0woPjkKqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Data (X, y) \n",
        "\n",
        "http://scikit.ml/multilabeldnn.html#Multi-label-deep-learning-with-scikit-multilearn\n",
        "\n"
      ],
      "metadata": {
        "id": "FttSF77Iw8oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fmodelpath = f'{modeldir}/fasttext.model'\n",
        "ypath = f'{datadir}/category/category_labels_v2.pkl'"
      ],
      "metadata": {
        "id": "JkKDJX3cFDqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib \n",
        "from collections import defaultdict\n",
        "LabelsList = joblib.load(ypath)"
      ],
      "metadata": {
        "id": "kisYJvFXFG3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CatsDict = defaultdict(list)\n",
        "for x in LabelsList:\n",
        "  # print(x.keys())\n",
        "  for cat in x['product']:\n",
        "    # print(x['name'])\n",
        "    CatsDict[cat].append(x['name'])"
      ],
      "metadata": {
        "id": "kp3cNZyoFI78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "print('# of categories:', len(CatsDict.keys()))\n",
        "for k, v in CatsDict.items():\n",
        "  print(f\"Category: {k}, Length: {len(v)}, \\nExamples:{random.sample(v, min(10, len(v)))}\")\n",
        "  print('---------------')\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5a8B4wVF0t6",
        "outputId": "11d1b54c-091e-4e14-f040-30b38d7112c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of categories: 217\n",
            "Category: 人工淚液, Length: 121, \n",
            "Examples:['750390@信東舒眼人工淚液0.5ml*20支', '視舒坦人工淚液點眼液 10ML', '(M/R)麗眼舒單支裝點眼液0', 'Rohto乾眼淚液', '(R)視舒坦單支裝人工', '博士倫舒視能單支裝舒潤液 30支入【康是美】', 'Sato 視樂眼液15', '(R)愛爾康淚然人工淚', '※(OTC)視舒坦單支裝人工淚液Systane ultra', '視舒坦人工淚液點眼液0.5m']\n",
            "---------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(f\"{datadir}/category/category_dictionary.json\", \"w\") as outfile:\n",
        "    json.dump(CatsDict, outfile, ensure_ascii = False, indent = 4)"
      ],
      "metadata": {
        "id": "u3zqNcOSHrKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DyLY5XxGV6Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# average the token vectors to form X's feature vector\n",
        "# use the binary tuple as label\n",
        "from gensim.models import FastText\n",
        "# should save keyedvectors only if there's no further training \n",
        "model = FastText.load(fmodelpath) "
      ],
      "metadata": {
        "id": "Z_SgjPyAw_gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## segmented, should have saved the segmented results for this\n",
        "# !pip install -q -U ckip-transformers\n",
        "# from ckip_transformers.nlp import CkipWordSegmenter\n",
        "# ws_driver = CkipWordSegmenter(level=3, device = 0)\n",
        "# name_texts = [x['name'] for x in LabelsList]\n",
        "# ws = ws_driver(name_texts) !nvidia-smi # k80要20分鐘"
      ],
      "metadata": {
        "id": "Gp6w_Mlb0gOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# parameters\n",
        "emb_dim = 200 # (see notebook 12.0)\n",
        "Xlen = len(LabelsList)\n",
        "nclass = len(LabelsList[0]['labels'])\n",
        "\n",
        "# make X(Emb matrix), y (label matrix)\n",
        "Emb = np.zeros((Xlen, emb_dim))\n",
        "Labels = np.zeros((Xlen, nclass))\n",
        "\n",
        "def get_avg_embeddings(tokenlist):\n",
        "  # if no token has embedding available, yields np.zeros(emb_dim)\n",
        "  return np.mean([model.wv[tok] if tok in model.wv else np.zeros(emb_dim) for tok in tokenlist], axis = 0)\n",
        "\n",
        "def get_weighted_embeddings(tokenlist):\n",
        "  # ref: https://stackoverflow.com/questions/29330792/weighted-averaging-a-list\n",
        "  rate = np.ones(len(tokenlist))\n",
        "  mid = int(len(rate)/2)\n",
        "  # category name通常出現在產品名稱後半部\n",
        "  rate = np.append(rate[:mid], (rate[mid:]+1))\n",
        "  # print(rate)\n",
        "  X = [model.wv[tok] if tok in model.wv else np.zeros(emb_dim) for tok in tokenlist]\n",
        "  return np.average(X, \n",
        "                    axis = 0,\n",
        "                    weights=rate)"
      ],
      "metadata": {
        "id": "hGdSlaU1zZxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(Xlen):\n",
        "    Emb[i,:] = get_weighted_embeddings(LabelsList[i]['seg_name'])\n",
        "    Labels[i,:] = LabelsList[i]['labels']"
      ],
      "metadata": {
        "id": "RJm5jX1BLFzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_weighted_embeddings(['黑人','牙膏'])"
      ],
      "metadata": {
        "id": "4o64wr8FK9Gi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d02a39-503a-4bbb-d0b6-8c8f1a010a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.32247051, -0.32322059, -0.70355904,  2.07394052,  2.14516916,\n",
              "       -1.69316   ,  2.09346946, -0.72159924, -1.41702869,  1.0934815 ,\n",
              "        1.49317399,  0.0466401 ,  1.01135514, -0.81285715, -0.69938417,\n",
              "        0.3276531 , -0.16764755, -0.01113643, -0.16000227, -0.47312679,\n",
              "       -1.03419837, -0.51314718,  0.48273041,  1.22986977, -1.94230157,\n",
              "       -1.54858735,  2.95696082,  0.08220889, -0.93612036, -2.0776791 ,\n",
              "       -0.28581977,  0.11455089, -0.23082522,  0.97293643,  0.28760044,\n",
              "        0.96373625, -1.6524392 ,  3.69620971,  0.22831683, -1.61783663,\n",
              "       -0.65232239,  0.2443138 , -0.66612804, -1.91881184, -0.50354154,\n",
              "       -0.30937341,  0.36371383,  1.54410291,  4.29339623,  2.54499979,\n",
              "        0.41443558,  1.246618  , -0.53838086,  1.87320554, -0.69987931,\n",
              "       -2.23694323, -0.31305675,  1.00335614, -0.24181277,  0.20122028,\n",
              "       -1.17844717, -1.39400069, -1.93530732, -1.77534568,  2.95400822,\n",
              "        1.97300873,  2.90354705, -1.89682297, -1.6842713 ,  3.22432311,\n",
              "        1.10427694, -3.87073696,  0.72155162,  0.25160292, -0.39707043,\n",
              "       -0.93945842,  2.35314548,  0.21868847, -0.19962329,  0.65844546,\n",
              "        0.76480793,  0.82107349, -0.8828151 , -2.20243686,  0.09725495,\n",
              "       -1.46375254, -0.98253433, -0.18597754,  2.31024047,  3.23933258,\n",
              "        0.13945871,  2.0192566 ,  1.57996019,  2.93160739, -3.58571271,\n",
              "        1.77199243,  0.55137576, -2.49456618, -2.26495114, -0.73376425,\n",
              "       -1.61471202, -1.06814329, -1.27008458,  1.85881506, -2.04785598,\n",
              "       -1.40792191,  0.0340207 , -0.31335807,  1.40417471, -2.41343192,\n",
              "       -0.6519676 ,  0.06158022,  1.30052593, -1.16383139,  1.30075673,\n",
              "       -0.45388444, -3.49854716,  1.73841347,  0.9512736 , -3.15145977,\n",
              "       -0.53293514,  1.58547411,  0.0949629 ,  0.4642579 , -0.30767234,\n",
              "       -0.57831355,  0.50771752,  1.60455973, -1.15416172,  0.6189156 ,\n",
              "       -3.2004993 ,  2.65083547,  0.25599228, -1.28617227, -1.05209378,\n",
              "        0.88398619, -0.29033612,  1.28889928, -2.27306777,  0.30049948,\n",
              "        2.29843851,  3.21896299, -0.25833906,  0.8019362 , -0.38868686,\n",
              "       -2.13517221, -0.99855853,  3.77127965, -1.3848363 ,  0.36485694,\n",
              "       -0.38441396,  1.32716319, -1.93457361, -0.19771758,  1.83629926,\n",
              "       -1.81450648, -1.35239891, -0.07290378, -0.34304496,  0.67869395,\n",
              "       -0.74726449, -0.01445055,  1.05216753,  0.44636889,  0.18435181,\n",
              "        3.30098696, -1.61612618,  1.39100973, -2.15368336,  1.69675255,\n",
              "       -3.02469154, -0.096729  , -3.43516914, -1.15490425,  0.11158692,\n",
              "        0.12877675, -0.83013463,  0.17650237,  1.47223388,  0.75475213,\n",
              "        0.59428938,  2.26032882,  0.053347  ,  2.90304982, -0.66170122,\n",
              "        0.74954756,  3.31289073, -1.48872978,  0.69722847, -0.4626314 ,\n",
              "        0.36674751,  0.8912651 ,  2.80592783,  0.11917344, -1.63323208,\n",
              "       -2.20008085,  0.54429166,  0.53984743, -0.04394988,  0.07402219])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.wv['黑人'])\n",
        "print(model.wv['牙膏'])"
      ],
      "metadata": {
        "id": "kwUMWE2TLQyw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c9c052-59b2-4732-e731-6199ef05672c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.5489779  -0.39174908 -0.330629    0.6661055   0.6256692  -0.1446274\n",
            "  0.20171165  0.5533052  -0.95217854  1.2505952  -0.28921488  0.64008945\n",
            "  0.85936373 -0.48164427 -0.12731491  0.5615754   0.30188504 -0.07759612\n",
            "  0.35072374 -0.33762568 -0.27788594 -0.85254127 -0.21423523 -0.05245302\n",
            "  0.0160771   0.05456965  0.5865492  -0.50909364 -0.28784016 -0.8009508\n",
            "  0.5128217  -0.5685834  -0.45796877  0.04401051  0.36486688  0.49517354\n",
            " -1.2559731   1.8368772   0.58585787 -0.6956234  -0.76854163 -0.25020218\n",
            " -0.69865394 -1.5215093  -0.1395044  -0.22810875  0.85111356  0.77385926\n",
            "  1.6878211   0.43676957  1.0313563   0.16242279  0.454149    1.1793333\n",
            " -0.5056054  -0.4782843  -0.24404621 -0.23599458  0.07155167 -0.0897591\n",
            " -0.78272724  0.09441853 -0.18591255 -0.78110373  0.2967342   0.06642801\n",
            "  1.6636679  -0.9008466   0.4922372   2.0589561   0.81139314 -1.0007845\n",
            " -0.38927853 -0.26854435 -0.4600889  -0.32442346  1.5665947  -0.8503532\n",
            " -1.2809393  -0.42920536 -0.26822165  0.62158597 -0.49669236 -0.73385173\n",
            " -0.8732064  -0.37802824 -0.7777915  -0.3197926   0.5569979   0.6760017\n",
            "  0.06045858  0.15425637  0.14359953  0.7968697  -1.2074364   0.6525499\n",
            " -0.04109905  0.28316766 -0.18573114 -1.2038401  -0.80034    -1.2942002\n",
            " -0.59941113  0.38834056 -0.2706975   0.04544508  0.35284883  1.1061716\n",
            "  0.87777203 -1.171441    0.95627284  0.865158   -0.14842716 -0.44052005\n",
            " -0.4540888   1.4680302  -0.62853503  0.338036    0.16985296  1.0336483\n",
            "  0.8229017   0.36626035 -0.45329252  0.32649618  0.30356717  0.7835263\n",
            " -0.48668793  0.380949    0.1794416  -0.22153865 -1.0810816   0.94727266\n",
            " -0.07820718  0.66571176  0.50207484  0.2555672  -0.46616024  0.49258858\n",
            " -0.70532316 -1.3024908   0.87727344  2.2077045  -1.0278941   0.03727116\n",
            " -0.7844862  -1.0117273   0.2327604   1.9455137   0.4941861  -0.5081832\n",
            " -0.20855393  0.39772168  0.7091385  -0.52680904  1.107305   -0.12768158\n",
            " -0.64090645 -0.23924462 -0.12035563 -0.1560809   0.25911275  0.01058877\n",
            "  0.7094768  -0.40392423 -0.27371773  0.10900221 -1.1470557   1.0038595\n",
            " -0.79838663  0.46236134 -1.0346955   0.4000833  -0.81360126  0.01914679\n",
            "  0.2725432   0.16079688 -0.9720712   0.00690622  0.2460273  -0.0758849\n",
            "  0.7833449   0.16081634 -0.0832852   0.40675744  0.03565115  1.3943155\n",
            "  1.0239288  -0.02548215  0.8780384  -0.08866828  0.11165778 -0.49994364\n",
            "  1.3028243   0.32857656 -0.595363    0.3839293   0.83812547 -0.73387605\n",
            " -0.76731133 -0.62671393]\n",
            "[-1.2581947  -0.28895634 -0.89002407  2.777858    2.9049191  -2.4674263\n",
            "  3.0393484  -1.3590515  -1.6494538   1.0149246   2.3843684  -0.25008458\n",
            "  1.0873508  -0.9784636  -0.9854188   0.21069194 -0.40241385  0.02209342\n",
            " -0.41536528 -0.54087734 -1.4123546  -0.34345013  0.83121324  1.8710312\n",
            " -2.921491   -2.3501658   4.1421666   0.37786016 -1.2602605  -2.7160432\n",
            " -0.6851405   0.45611805 -0.11725345  1.4373994   0.24896722  1.1980176\n",
            " -1.8506722   4.625876    0.04954631 -2.0789433  -0.5942128   0.49157178\n",
            " -0.6498651  -2.117463   -0.6855601  -0.35000575  0.12001397  1.9292247\n",
            "  5.596184    3.599115    0.1059752   1.7887156  -1.0346458   2.2201416\n",
            " -0.79701626 -3.1162727  -0.34756202  1.6230315  -0.398495    0.34670997\n",
            " -1.3763071  -2.1382103  -2.8100047  -2.2724667   4.282645    2.926299\n",
            "  3.5234866  -2.3948112  -2.7725255   3.8070066   1.2507188  -5.305713\n",
            "  1.2769667   0.51167655 -0.3655612  -1.2469759   2.7464209   0.7532093\n",
            "  0.34103474  1.2022709   1.2813227   0.92081726 -1.0758765  -2.9367294\n",
            "  0.5824856  -2.0066147  -1.0849057  -0.11907001  3.1868618   4.520998\n",
            "  0.17895877  2.9517567   2.2981405   3.9989762  -4.774851    2.3317137\n",
            "  0.84761316 -3.883433   -3.3045611  -0.4987263  -2.021898   -0.95511484\n",
            " -1.6054213   2.5940523  -2.9364352  -2.1346054  -0.12539336 -1.0231229\n",
            "  1.667376   -3.0344274  -1.4560878  -0.34020868  2.0250025  -1.5254871\n",
            "  2.1781795  -1.4148418  -4.933553    2.4386022   1.3419839  -5.244014\n",
            " -1.2108536   2.195081    0.36909062  0.53313875 -0.6132921  -1.2592335\n",
            "  1.0049202   2.216365   -1.8209634   1.0391427  -4.260208    3.502617\n",
            "  0.423092   -2.2621143  -1.8291781   1.1981957  -0.20242406  1.6870546\n",
            " -3.05694     1.1019946   3.009021    3.7245922   0.12643848  1.1842687\n",
            " -0.1907872  -2.6968946  -1.614218    4.6841626  -2.3243475   0.801377\n",
            " -0.47234398  1.791884   -3.2564297  -0.03317185  2.2007964  -2.657919\n",
            " -1.7081451   0.01026664 -0.45438963  1.0960814  -1.2504531  -0.02697022\n",
            "  1.2235129   0.87151545  0.41338658  4.8969793  -1.8506614   1.5845848\n",
            " -2.8313317   2.3139482  -4.0196896  -0.34513515 -4.745953   -1.7419298\n",
            "  0.03110878  0.11276669 -0.75916636  0.26130044  2.0853372   1.1700706\n",
            "  0.4997616   3.310085    0.12166309  4.151196   -1.0103774   0.4271636\n",
            "  4.4573717  -2.2203536   0.6068235  -0.64961296  0.49429238  1.5868695\n",
            "  3.5574796   0.01447188 -2.1521666  -3.492086    0.39737475  1.1767092\n",
            "  0.31773084  0.42439026]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "stack a simple few-layer neural network "
      ],
      "metadata": {
        "id": "4CtUBbO2G1OQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U torch"
      ],
      "metadata": {
        "id": "sWEow1eo3WKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seeding; normally not working in colab\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "def seeding(myseed):\n",
        "  torch.manual_seed(myseed)\n",
        "  torch.cuda.manual_seed(myseed)\n",
        "  torch.cuda.manual_seed_all(myseed)\n",
        "  np.random.seed(myseed)\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "yWKB3A0X4ctR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "MYSEED = 42\n",
        "TESTRATIO = 0.2 \n",
        "DROPOUT = 0.5\n",
        "BATCHSIZE = 200 \n",
        "## Category數：nclass (217) fixed value\n",
        "seeding(MYSEED)"
      ],
      "metadata": {
        "id": "eo7pzhL13wS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# 一些分工：做k-fold、\n",
        "X_train, X_test, y_train, y_test = train_test_split(Emb, Labels, \n",
        "                                                    test_size=TESTRATIO, \n",
        "                                                    random_state= MYSEED)\n",
        "input_dim = X_train.shape[1]\n",
        "hd1, hd2 = 128, 256 \n",
        "output_dim = nclass \n",
        "# originally len(np.unique(y_train.rows)) as http://scikit.ml/multilabeldnn.html#Multi-label-deep-learning-with-scikit-multilearn \n",
        "# states, but the logic is (if I understand it correctly) very weird"
      ],
      "metadata": {
        "id": "IfIk9-A4jE9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CatDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = torch.from_numpy(X).float()\n",
        "        if y is not None:\n",
        "            y = y.astype(np.int)\n",
        "            self.label = torch.from_numpy(y).float()\n",
        "        else:\n",
        "            self.label = None\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ],
      "metadata": {
        "id": "VJrMKgNNCckM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = BATCHSIZE\n",
        "train_set = CatDataset(X_train, y_train)\n",
        "val_set = CatDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "NHhkPETyC2yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture(s): Simple Network (linear layers)\n"
      ],
      "metadata": {
        "id": "hKme9QQeOg7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLabelClassifier(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim=input_dim,\n",
        "            hd1 = hd1,\n",
        "            hd2 = hd2,\n",
        "            output_dim=output_dim,\n",
        "            dropout=DROPOUT,\n",
        "    ):\n",
        "        super(MultiLabelClassifier, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # 只有兩層fc layers (shallow)，主要是看fasttext embedding的效果\n",
        "        self.hidden1 = nn.Linear(input_dim, hd1)\n",
        "        self.hidden2 = nn.Linear(hd1, hd2)\n",
        "        self.output = nn.Linear(hd2, output_dim)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "        X = self.hidden1(X)\n",
        "        X = self.hidden2(X)\n",
        "        X = F.relu(X)\n",
        "        X = self.dropout(X)\n",
        "        # 過softmax拿機率值\n",
        "        X = F.softmax(self.output(X), dim=-1)\n",
        "        return X"
      ],
      "metadata": {
        "id": "wMuzAv4v4_YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "References: \n",
        "https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
        "https://towardsdatascience.com/\n",
        "\n",
        "lstm-text-classification-using-pytorch-2c6c657f8fc0\n",
        "\n",
        "My machine learning assignments"
      ],
      "metadata": {
        "id": "kvLa_WTeR4e8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from skmultilearn.problem_transform import LabelPowerset\n",
        "# training parameters\n",
        "THRESHOLD = 0.3\n",
        "EPOCHS = 50\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "learning_rate = 5e-4       # learning rate\n",
        "net = MultiLabelClassifier().to(device)\n",
        "criterion = nn.BCELoss() \n",
        "weight_decay = 0.1\n",
        "optimizer = torch.optim.AdamW(net.parameters(), \n",
        "                              lr=learning_rate, \n",
        "                              weight_decay=weight_decay)"
      ],
      "metadata": {
        "id": "p-dS9kqY6njW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "2iAZwCtUKQVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BrM0nSYU4vcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time, datetime\n",
        "from datetime import date, datetime\n",
        "now = datetime.now()\n",
        "model_prefix = now.strftime(\"%m%d-%H%M\")\n",
        "MODELPATH = f'{maindir}/multi_label/{model_prefix}.ckpt'\n",
        "MODELPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IFObn-MC3T_j",
        "outputId": "adbbf523-bbdf-4602-a887-2ac0490123e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/FinTech-final-project/multi_label/0427-1353.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "METHOD =( 'macro', 'weighted')"
      ],
      "metadata": {
        "id": "XqcXMcTgG9Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "from sklearn.metrics import f1_score\n",
        "best_val_acc = 0.0\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_acc, val_acc, val_weighted_acc = 0.0, 0.0, 0.0\n",
        "    train_loss, val_loss = 0.0,0.0\n",
        "    # training\n",
        "    net.train() # set the model to training mode\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "        # print('l:', labels.shape)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad() \n",
        "        outputs = net(inputs) \n",
        "        # print('o:', outputs.shape, 'l:', labels.shape)\n",
        "        batch_loss = criterion(outputs, labels)\n",
        "        \n",
        "        # THRESHOLD: all labels with probabilities higher than it are considered predicted labels \n",
        "        # and others are skipped. We are using a threshold value of 0.5.\n",
        "        pred = np.array(outputs.cpu().detach().numpy() > THRESHOLD, dtype=float)\n",
        "        labels = labels.cpu().detach().numpy()\n",
        "        # train_acc += getbatchf1(labels, pred)\n",
        "        # print(f1_score(labels, pred, average='macro'))\n",
        "        # compute macro_f1\n",
        "        # print(labels.shape, pred.shape)\n",
        "        # print(f1_score(labels, pred, average='macro'))\n",
        "        batch_loss.backward() \n",
        "        optimizer.step() \n",
        "        train_loss += batch_loss.item()\n",
        "\n",
        "    # validation\n",
        "    if len(val_set) > 0:\n",
        "        net.eval() # set the model to evaluation mode\n",
        "        val_preds, val_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(val_loader):\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs =net(inputs)\n",
        "                batch_loss = criterion(outputs, labels) \n",
        "                val_pred = np.array(outputs.cpu().detach().numpy() > THRESHOLD, dtype=float)\n",
        "                labels = labels.cpu().detach().numpy()\n",
        "                val_loss += batch_loss.item()\n",
        "                val_preds.append(val_pred)\n",
        "                val_labels.append(labels)\n",
        "            val_labels, val_preds = np.vstack(val_labels), np.vstack(val_preds)\n",
        "            val_acc = f1_score(val_labels, val_preds, average = METHOD[0])\n",
        "            val_weighted_acc = f1_score(val_labels, val_preds, average = METHOD[1])\n",
        "            \n",
        "            if val_acc > best_val_acc:\n",
        "              torch.save(net.state_dict(), MODELPATH)\n",
        "              best_val_acc = val_acc\n",
        "            print('[{:03d}/{:03d}] Loss: {:3.4f} || VLoss: {:3.4f} | Val macro f1: {:3.4f}, weighted f1: {:3.4f}.'.format(\n",
        "                epoch + 1, EPOCHS, \n",
        "                train_loss/len(train_loader), \n",
        "                val_loss/len(val_loader),\n",
        "                val_acc, \n",
        "                val_weighted_acc,\n",
        "            ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DptuDrTNBFri",
        "outputId": "e9c07591-2797-4c60-ab1c-55edf862bef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[001/050] Loss: 0.0106 || VLoss: 0.0087 | Val macro f1: 0.3161, weighted f1: 0.6127.\n",
            "[002/050] Loss: 0.0092 || VLoss: 0.0079 | Val macro f1: 0.3739, weighted f1: 0.6580.\n",
            "[003/050] Loss: 0.0085 || VLoss: 0.0074 | Val macro f1: 0.4079, weighted f1: 0.6882.\n",
            "[004/050] Loss: 0.0080 || VLoss: 0.0070 | Val macro f1: 0.4304, weighted f1: 0.7051.\n",
            "[005/050] Loss: 0.0077 || VLoss: 0.0067 | Val macro f1: 0.4520, weighted f1: 0.7181.\n",
            "[006/050] Loss: 0.0075 || VLoss: 0.0066 | Val macro f1: 0.4651, weighted f1: 0.7276.\n",
            "[007/050] Loss: 0.0072 || VLoss: 0.0064 | Val macro f1: 0.4792, weighted f1: 0.7370.\n",
            "[008/050] Loss: 0.0070 || VLoss: 0.0062 | Val macro f1: 0.4867, weighted f1: 0.7419.\n",
            "[009/050] Loss: 0.0069 || VLoss: 0.0061 | Val macro f1: 0.4969, weighted f1: 0.7493.\n",
            "[010/050] Loss: 0.0068 || VLoss: 0.0060 | Val macro f1: 0.5043, weighted f1: 0.7542.\n",
            "[011/050] Loss: 0.0066 || VLoss: 0.0059 | Val macro f1: 0.5061, weighted f1: 0.7569.\n",
            "[012/050] Loss: 0.0066 || VLoss: 0.0058 | Val macro f1: 0.5127, weighted f1: 0.7626.\n",
            "[013/050] Loss: 0.0065 || VLoss: 0.0057 | Val macro f1: 0.5204, weighted f1: 0.7671.\n",
            "[014/050] Loss: 0.0064 || VLoss: 0.0057 | Val macro f1: 0.5235, weighted f1: 0.7681.\n",
            "[015/050] Loss: 0.0063 || VLoss: 0.0056 | Val macro f1: 0.5288, weighted f1: 0.7736.\n",
            "[016/050] Loss: 0.0062 || VLoss: 0.0055 | Val macro f1: 0.5315, weighted f1: 0.7746.\n",
            "[017/050] Loss: 0.0062 || VLoss: 0.0055 | Val macro f1: 0.5311, weighted f1: 0.7760.\n",
            "[018/050] Loss: 0.0061 || VLoss: 0.0055 | Val macro f1: 0.5378, weighted f1: 0.7773.\n",
            "[019/050] Loss: 0.0061 || VLoss: 0.0054 | Val macro f1: 0.5414, weighted f1: 0.7806.\n",
            "[020/050] Loss: 0.0060 || VLoss: 0.0054 | Val macro f1: 0.5483, weighted f1: 0.7836.\n",
            "[021/050] Loss: 0.0060 || VLoss: 0.0053 | Val macro f1: 0.5501, weighted f1: 0.7853.\n",
            "[022/050] Loss: 0.0059 || VLoss: 0.0053 | Val macro f1: 0.5536, weighted f1: 0.7867.\n",
            "[023/050] Loss: 0.0059 || VLoss: 0.0053 | Val macro f1: 0.5531, weighted f1: 0.7867.\n",
            "[024/050] Loss: 0.0058 || VLoss: 0.0052 | Val macro f1: 0.5586, weighted f1: 0.7884.\n",
            "[025/050] Loss: 0.0058 || VLoss: 0.0052 | Val macro f1: 0.5608, weighted f1: 0.7902.\n",
            "[026/050] Loss: 0.0057 || VLoss: 0.0052 | Val macro f1: 0.5642, weighted f1: 0.7923.\n",
            "[027/050] Loss: 0.0057 || VLoss: 0.0052 | Val macro f1: 0.5565, weighted f1: 0.7920.\n",
            "[028/050] Loss: 0.0057 || VLoss: 0.0051 | Val macro f1: 0.5659, weighted f1: 0.7950.\n",
            "[029/050] Loss: 0.0056 || VLoss: 0.0051 | Val macro f1: 0.5686, weighted f1: 0.7976.\n",
            "[030/050] Loss: 0.0056 || VLoss: 0.0050 | Val macro f1: 0.5751, weighted f1: 0.7992.\n",
            "[031/050] Loss: 0.0056 || VLoss: 0.0050 | Val macro f1: 0.5778, weighted f1: 0.8007.\n",
            "[032/050] Loss: 0.0055 || VLoss: 0.0050 | Val macro f1: 0.5790, weighted f1: 0.8007.\n",
            "[033/050] Loss: 0.0055 || VLoss: 0.0050 | Val macro f1: 0.5793, weighted f1: 0.8026.\n",
            "[034/050] Loss: 0.0055 || VLoss: 0.0049 | Val macro f1: 0.5751, weighted f1: 0.8038.\n",
            "[035/050] Loss: 0.0055 || VLoss: 0.0049 | Val macro f1: 0.5853, weighted f1: 0.8052.\n",
            "[036/050] Loss: 0.0054 || VLoss: 0.0049 | Val macro f1: 0.5806, weighted f1: 0.8032.\n",
            "[037/050] Loss: 0.0054 || VLoss: 0.0049 | Val macro f1: 0.5828, weighted f1: 0.8048.\n",
            "[038/050] Loss: 0.0054 || VLoss: 0.0049 | Val macro f1: 0.5890, weighted f1: 0.8057.\n",
            "[039/050] Loss: 0.0054 || VLoss: 0.0048 | Val macro f1: 0.5895, weighted f1: 0.8077.\n",
            "[040/050] Loss: 0.0054 || VLoss: 0.0048 | Val macro f1: 0.5921, weighted f1: 0.8098.\n",
            "[041/050] Loss: 0.0053 || VLoss: 0.0048 | Val macro f1: 0.5885, weighted f1: 0.8086.\n",
            "[042/050] Loss: 0.0053 || VLoss: 0.0048 | Val macro f1: 0.5955, weighted f1: 0.8113.\n",
            "[043/050] Loss: 0.0053 || VLoss: 0.0048 | Val macro f1: 0.5982, weighted f1: 0.8118.\n",
            "[044/050] Loss: 0.0053 || VLoss: 0.0048 | Val macro f1: 0.5970, weighted f1: 0.8110.\n",
            "[045/050] Loss: 0.0052 || VLoss: 0.0048 | Val macro f1: 0.6038, weighted f1: 0.8127.\n",
            "[046/050] Loss: 0.0052 || VLoss: 0.0047 | Val macro f1: 0.6023, weighted f1: 0.8124.\n",
            "[047/050] Loss: 0.0052 || VLoss: 0.0047 | Val macro f1: 0.5990, weighted f1: 0.8136.\n",
            "[048/050] Loss: 0.0052 || VLoss: 0.0047 | Val macro f1: 0.5926, weighted f1: 0.8107.\n",
            "[049/050] Loss: 0.0052 || VLoss: 0.0047 | Val macro f1: 0.5990, weighted f1: 0.8127.\n",
            "[050/050] Loss: 0.0052 || VLoss: 0.0047 | Val macro f1: 0.6004, weighted f1: 0.8121.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **對這結果的檢視與說明：**\n",
        "https://www.notion.so/4-27-macro-f1-on-multi-label-5c9e0534efe94cc8a526246f66f213e5"
      ],
      "metadata": {
        "id": "N6Ohp2fGL-_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, classification_report\n",
        "# multilabel classification\n",
        "y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1], [1,0,0]]\n",
        "y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0], [1,0,1]]\n",
        "\n",
        "sc = 0\n",
        "for a, b in zip(y_true, y_pred):\n",
        "  sc+=f1_score(a, b, average = 'macro')\n",
        "sc/=len(y_true)"
      ],
      "metadata": {
        "id": "xx4r7mIC9iBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "f1_score(y_true, y_pred, average='macro') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9AhcKpJ5We9",
        "outputId": "9c053c03-8854-47a6-fe76-08cd6a699232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.eval()\n",
        "val_preds, val_labels = [], []\n",
        "for i, data in enumerate(val_loader):\n",
        "      inputs, labels = data\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      outputs =net(inputs)\n",
        "      val_pred = np.array(outputs.cpu().detach().numpy() > THRESHOLD, dtype=float)\n",
        "      labels = labels.cpu().detach().numpy()\n",
        "      val_preds.append(val_pred)\n",
        "      val_labels.append(labels)"
      ],
      "metadata": {
        "id": "KSiRtn2C2dpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_preds = np.vstack(val_preds)\n",
        "val_labels = np.vstack(val_labels)\n",
        "val_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTiHVkwXSIgN",
        "outputId": "15417a34-8f81-485b-8289-5903d5fa091f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18462, 217)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc = f1_score(val_labels, val_preds, average = METHOD[0])\n",
        "val_weighted_acc = f1_score(val_labels, val_preds, average = METHOD[1])\n",
        "print(f'macro f1: {val_acc:.4f}')\n",
        "print(f'weighted f1: {val_weighted_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GugsRVQOSNYF",
        "outputId": "fed4bb21-57ed-4169-8e99-1a223a5946ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "macro f1: 0.6070\n",
            "weighted f1: 0.8159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat2idx = joblib.load(f'{datadir}/category/cat2idx.pkl')\n",
        "labels = sorted(cat2idx.items(), key = lambda x:x[1])\n",
        "print(labels[:5])\n",
        "keys = [x[0] for x in labels]\n",
        "keys[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlC3urzxWNjD",
        "outputId": "4be02d13-6f1a-48dd-f1e3-f8f31e8080cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('人工淚液', 0), ('中式香腸', 1), ('化妝水', 2), ('成人牙膏', 3), ('水路/健行鞋', 4)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['人工淚液', '中式香腸', '化妝水', '成人牙膏', '水路/健行鞋']"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(val_labels, val_preds, target_names= keys))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO8MB-A5Ushj",
        "outputId": "6ea20a26-a4be-4dee-a755-7682790356c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        人工淚液       0.86      0.46      0.60        13\n",
            "        中式香腸       0.72      0.91      0.80        53\n",
            "         化妝水       0.75      0.84      0.79       181\n",
            "        成人牙膏       0.97      0.97      0.97       381\n",
            "      水路/健行鞋       0.00      0.00      0.00         1\n",
            "         火鍋料       0.73      0.58      0.65        62\n",
            "          奶瓶       0.90      0.97      0.94        38\n",
            "        巧拼地墊       0.00      0.00      0.00         3\n",
            "        平板電腦       0.65      0.61      0.63        28\n",
            "       筆記型電腦       0.98      0.81      0.89        67\n",
            "       智慧型手機       0.78      0.95      0.85       164\n",
            "    瓦斯爐(廚房用)       0.17      0.22      0.19         9\n",
            "    瓦斯爐(攜帶式)       0.75      0.32      0.44        19\n",
            "       甲片/甲貼       1.00      0.83      0.91        52\n",
            "         甲油膠       0.50      0.17      0.25         6\n",
            "          冰箱       0.79      0.83      0.81        41\n",
            "        安全汽座       1.00      0.30      0.46        10\n",
            "        成人牙刷       0.91      0.97      0.94       262\n",
            "        成人奶粉       0.84      0.97      0.90        93\n",
            "        兒童牙刷       0.73      0.75      0.74        64\n",
            "       成人紙尿褲       1.00      0.93      0.96        58\n",
            "      成長幼兒奶粉       0.74      0.82      0.78        28\n",
            "        媽媽奶粉       0.00      0.00      0.00         6\n",
            "         收納櫃       0.94      0.94      0.94        65\n",
            "      米漿/豆米漿       0.00      0.00      0.00        23\n",
            "          羊乳       0.00      0.00      0.00         3\n",
            "        西式香腸       0.55      0.59      0.57        27\n",
            "     冷氣/冷暖空調       1.00      1.00      1.00        12\n",
            "        即食雞胸       1.00      0.53      0.70        15\n",
            "        即飲奶茶       0.81      0.89      0.85        92\n",
            "        即飲咖啡       0.87      0.77      0.82        93\n",
            "         洗髮精       0.91      0.98      0.94       779\n",
            "         咖啡豆       0.90      0.87      0.89        63\n",
            "        即飲紅茶       0.88      0.84      0.86       128\n",
            "       即飲無糖茶       0.88      0.47      0.61        98\n",
            "       即飲烏龍茶       0.86      0.73      0.79        33\n",
            "        即飲綠茶       0.85      0.93      0.88       120\n",
            "        即溶咖啡       0.70      0.88      0.78       130\n",
            "          眉筆       0.77      0.88      0.82       176\n",
            "         吸塵器       0.91      0.99      0.95       106\n",
            "         洗衣機       0.90      0.98      0.94        63\n",
            "         吹風機       0.99      0.96      0.97        92\n",
            "     妝前乳/隔離霜       0.56      0.63      0.59       123\n",
            "         快煮壺       0.76      0.75      0.75        55\n",
            "     快煮麵/乾拌麵       0.76      0.41      0.53       114\n",
            "         杏仁奶       1.00      0.11      0.20         9\n",
            "         沐浴乳       0.91      0.95      0.93       592\n",
            "         洗面乳       0.77      0.83      0.80       563\n",
            "         卸妝水       0.64      0.64      0.64        88\n",
            "         洗衣精       0.84      0.98      0.90       412\n",
            "         洗衣粉       0.82      0.77      0.79        78\n",
            " 洗髮精(嬰幼童/孕婦)       0.89      0.59      0.71        70\n",
            "          面膜       0.93      0.96      0.94       387\n",
            "       豆奶/豆乳       1.00      0.06      0.11        53\n",
            "      豆漿/黑豆漿       0.63      0.74      0.68        61\n",
            "        身體乳液       0.57      0.53      0.55        83\n",
            "          防曬       0.74      0.62      0.68       104\n",
            "         乳酸菌       0.50      0.25      0.33         4\n",
            "        兒童牙膏       0.84      0.98      0.91        59\n",
            "       兒童漱口水       0.75      0.94      0.83        16\n",
            "    其他地墊(家用)       0.63      0.36      0.46        33\n",
            "         卸甲液       0.00      0.00      0.00         0\n",
            "         卸妝乳       0.73      0.26      0.38        31\n",
            "         卸妝油       1.00      0.13      0.24        52\n",
            "         卸妝棉       0.94      0.85      0.89        54\n",
            "        卸妝凝膠       1.00      0.32      0.48        22\n",
            "        卸妝濕巾       0.00      0.00      0.00         2\n",
            "         卸妝霜       1.00      0.12      0.22         8\n",
            "         卸妝露       0.00      0.00      0.00         1\n",
            "         咖啡機       1.00      0.79      0.88        29\n",
            "          鍋具       0.75      0.84      0.79       297\n",
            "         果汁機       1.00      0.15      0.26        20\n",
            "       狗乾糧罐頭       0.68      0.72      0.70       294\n",
            "         狗零食       0.69      0.61      0.65        96\n",
            "         芳香豆       0.92      0.92      0.92        36\n",
            "         保久乳       0.79      0.72      0.76        43\n",
            "         保溫杯       0.00      0.00      0.00         0\n",
            "         保險套       0.93      1.00      0.96       111\n",
            "        前導精華       1.00      0.33      0.50         3\n",
            "        眼部精華       0.00      0.00      0.00        10\n",
            "         精華液       0.64      0.77      0.70       155\n",
            "         指甲油       0.99      0.97      0.98       164\n",
            "         按摩椅       1.00      0.25      0.40         4\n",
            "         染眉膏       0.87      0.53      0.66        38\n",
            "         柔軟精       0.92      0.87      0.89        67\n",
            "         洗衣皂       0.83      0.32      0.47        31\n",
            "         洗衣球       0.93      0.93      0.93        81\n",
            "          眼霜       0.84      0.51      0.63        61\n",
            "         洗碗機       0.00      0.00      0.00         0\n",
            "          眉粉       0.78      0.23      0.36        30\n",
            "         眉膠筆       0.67      0.12      0.21        16\n",
            "       面霜/乳霜       0.67      0.63      0.65       271\n",
            "         香氛機       1.00      0.11      0.20         9\n",
            "        香氛蠟燭       0.81      0.77      0.79        22\n",
            "          修容       0.57      0.38      0.46        34\n",
            "         粉底液       0.87      0.87      0.87       154\n",
            "          粉餅       0.68      0.92      0.78       111\n",
            "         BB霜       1.00      0.50      0.67        20\n",
            "         CC霜       0.00      0.00      0.00        12\n",
            "        原味牛乳       0.00      0.00      0.00         4\n",
            "          唇彩       1.00      0.71      0.83        17\n",
            "         染唇液       0.00      0.00      0.00         0\n",
            "          唇釉       0.99      0.92      0.95        79\n",
            "         唇彩盤       0.00      0.00      0.00         1\n",
            "          唇膏       0.83      0.93      0.87       216\n",
            "          唇蜜       0.91      0.47      0.62        43\n",
            "         護唇膏       0.84      0.87      0.85       245\n",
            "         護手霜       0.87      0.85      0.86       189\n",
            "         唇線筆       1.00      0.60      0.75         5\n",
            "          唇露       0.92      0.71      0.80        17\n",
            "        桌上電腦       1.00      0.08      0.14        13\n",
            "         氣泡水       0.76      0.83      0.79       102\n",
            "         氣炸鍋       0.56      0.42      0.48        12\n",
            "         消毒鍋       1.00      0.20      0.33         5\n",
            "     烘衣機/乾衣機       1.00      0.38      0.56        13\n",
            "         烘碗機       0.81      0.52      0.63        25\n",
            "         烤肉架       0.00      0.00      0.00         3\n",
            "          烤箱       0.76      0.57      0.65        44\n",
            "       珪藻土地墊       0.88      0.72      0.79        32\n",
            "         益生菌       0.77      0.87      0.82        87\n",
            "         除濕機       0.96      0.95      0.96       106\n",
            "         健腹器       0.00      0.00      0.00         0\n",
            "       啞鈴/槓鈴       1.00      0.42      0.59        12\n",
            "          槓片       0.00      0.00      0.00         0\n",
            "          啤酒       0.84      0.80      0.82       407\n",
            "         熱水器       1.00      0.50      0.67        22\n",
            "       RTD調酒       0.88      0.59      0.71       114\n",
            "         眼影盤       0.84      0.88      0.86       138\n",
            "      速食麵/泡麵       0.80      0.94      0.86       473\n",
            "         醬油類       0.90      0.80      0.85       143\n",
            "       貓乾糧罐頭       0.60      0.93      0.73       388\n",
            "         精華油       0.00      0.00      0.00        18\n",
            "         貓零食       0.90      0.67      0.77        64\n",
            "        常溫醬包       0.71      0.78      0.75       251\n",
            "         掃地機       0.81      0.72      0.76        36\n",
            "        排油煙機       0.60      0.30      0.40        10\n",
            "        液晶電視       0.97      0.99      0.98        73\n",
            "       電視遊戲機       0.96      0.81      0.88        31\n",
            "     淨水器/濾水器       0.72      0.41      0.52        32\n",
            "         濕紙巾       0.91      0.98      0.95       317\n",
            "        眼唇卸妝       0.93      0.79      0.86        34\n",
            "        眼影打底       0.00      0.00      0.00         4\n",
            "       眼影刷/棒       0.67      0.60      0.63        40\n",
            "         眼影筆       1.00      0.29      0.44         7\n",
            "         眼影蜜       0.00      0.00      0.00         7\n",
            "          腮紅       0.83      0.71      0.77        77\n",
            "         眼影霜       1.00      0.33      0.50         3\n",
            "         眼線液       0.72      0.93      0.81        46\n",
            "        眼線膠筆       0.85      0.80      0.82        44\n",
            "        眼線液筆       0.80      0.47      0.59        34\n",
            "         眼線筆       0.64      0.64      0.64        42\n",
            "         野餐墊       1.00      0.12      0.22         8\n",
            "        麥片穀類       0.86      0.82      0.84       111\n",
            "         燕麥奶       0.83      0.77      0.80        44\n",
            "         智慧錶       0.79      0.77      0.78        48\n",
            "          棉條       0.89      0.92      0.90        51\n",
            "      棉褲/安睡褲       0.88      0.71      0.79        21\n",
            "          湯圓       0.80      0.53      0.64        30\n",
            "           菸       0.89      0.92      0.91       368\n",
            "        碳酸飲料       0.73      0.82      0.77       213\n",
            "         跑步機       0.00      0.00      0.00        11\n",
            "    媽媽茶(哺乳茶)       0.00      0.00      0.00         3\n",
            "         微波爐       0.87      0.82      0.84        49\n",
            "          椰奶       0.00      0.00      0.00         8\n",
            "         溫奶器       1.00      0.33      0.50         3\n",
            "          滑鼠       0.94      0.96      0.95       249\n",
            "         瑜珈墊       0.00      0.00      0.00         4\n",
            "         睫毛膏       0.88      0.85      0.86        82\n",
            "          睡袋       0.79      0.88      0.84        43\n",
            "         葉黃素       0.86      0.89      0.88       108\n",
            "      維他命B+C       0.00      0.00      0.00        13\n",
            "          葉酸       0.00      0.00      0.00        12\n",
            "      運動/機能服       0.81      0.92      0.86       424\n",
            "        維他命B       0.68      0.79      0.73       106\n",
            "         運動鞋       0.89      0.90      0.90       423\n",
            "         電子鍋       0.81      0.90      0.85        42\n",
            "          電鍋       0.71      0.86      0.78        43\n",
            "         電風扇       0.84      0.59      0.69        44\n",
            "         電暖器       0.98      0.99      0.98       302\n",
            "         電磁爐       0.70      0.70      0.70        30\n",
            "        電熱水瓶       0.83      0.73      0.78        48\n",
            "         滴雞精       0.64      0.70      0.67        43\n",
            "          精油       0.88      0.75      0.81        40\n",
            "       維他命飲料       0.76      0.62      0.68        50\n",
            "        維他命D       0.00      0.00      0.00        13\n",
            "        維他命C       0.73      0.71      0.72        62\n",
            "          薑黃       0.64      0.51      0.57        35\n",
            "        維他命E       0.00      0.00      0.00         7\n",
            "        膠原蛋白       0.88      0.49      0.63        47\n",
            "          蜜粉       0.90      0.57      0.70       115\n",
            "         遮瑕膏       0.81      0.33      0.47        39\n",
            "        廚房紙巾       0.88      0.78      0.82        36\n",
            "         潤髮乳       0.86      0.77      0.81       142\n",
            "         護髮乳       0.83      0.87      0.85       374\n",
            "         衛生紙       1.00      0.99      1.00       208\n",
            "         衛生棉       0.93      0.96      0.95       127\n",
            "        調味牛乳       0.67      0.73      0.70        67\n",
            "        調味豆漿       0.67      0.14      0.24        14\n",
            "         調理機       0.67      0.27      0.38        15\n",
            "         遮瑕液       0.67      0.47      0.55        17\n",
            "         遮瑕筆       1.00      0.33      0.50        12\n",
            "         遮瑕蜜       0.00      0.00      0.00         3\n",
            "         遮瑕盤       0.00      0.00      0.00         8\n",
            "        機能牛乳       1.00      0.08      0.14        13\n",
            "          鮮乳       0.84      0.85      0.84       147\n",
            "          優格       0.79      0.87      0.83        98\n",
            "         優酪乳       0.85      0.82      0.84        62\n",
            "       嬰幼手推車       0.00      0.00      0.00         3\n",
            "        嬰幼乳液       0.00      0.00      0.00         1\n",
            "        臉部乳液       0.69      0.73      0.71       168\n",
            "          鍵盤       0.92      0.91      0.92       105\n",
            "         擴香瓶       0.74      0.62      0.68        42\n",
            "     濾掛/耳掛咖啡       0.61      0.85      0.71        62\n",
            "          雞精       0.85      0.87      0.86        38\n",
            "         礦泉水       0.83      0.91      0.87       222\n",
            "        護唇精華       1.00      0.62      0.77         8\n",
            "         DD霜       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.82      0.82      0.82     18561\n",
            "   macro avg       0.70      0.57      0.60     18561\n",
            "weighted avg       0.82      0.82      0.81     18561\n",
            " samples avg       0.80      0.82      0.80     18561\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(keys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDBc1N7wX_Pn",
        "outputId": "aae9feec-ec0a-40c4-b042-6be229c5a771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "217"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking example reference: \n",
        "http://scikit.ml/multilabeldnn.html#Multi-label-deep-learning-with-scikit-multilearn\n",
        "(which doesn't seem to have the logic our task requires)"
      ],
      "metadata": {
        "id": "9_lOj32TJvZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install arff\n",
        "from skmultilearn.dataset import load_dataset\n",
        "X_train, y_train, feature_names, label_names = load_dataset('emotions', 'train')\n",
        "X_test, y_test, _, _ = load_dataset('emotions', 'test')"
      ],
      "metadata": {
        "id": "Aez1JtPm-4X7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}